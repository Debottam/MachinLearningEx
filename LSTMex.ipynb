{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import plot_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Data = [[[(i+j)] for i in range (5)]for j in range (100)]\n",
    "target = [(i+5) for i in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Data = np.array(Data, dtype = float)\n",
    "target = np.array(target, dtype = float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: (100, 5, 1)\n",
      "target shape: (100,)\n"
     ]
    }
   ],
   "source": [
    "print \"data shape:\", Data.shape\n",
    "print \"target shape:\", target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(Data, target, test_size = 0.2, random_state = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[80.],\n",
       "        [81.],\n",
       "        [82.],\n",
       "        [83.],\n",
       "        [84.]],\n",
       "\n",
       "       [[ 4.],\n",
       "        [ 5.],\n",
       "        [ 6.],\n",
       "        [ 7.],\n",
       "        [ 8.]],\n",
       "\n",
       "       [[81.],\n",
       "        [82.],\n",
       "        [83.],\n",
       "        [84.],\n",
       "        [85.]],\n",
       "\n",
       "       [[76.],\n",
       "        [77.],\n",
       "        [78.],\n",
       "        [79.],\n",
       "        [80.]]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:4,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([85.,  9., 86., 81.])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = x_train/100, x_test/100, y_train/100, y_test/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.8 ],\n",
       "        [0.81],\n",
       "        [0.82],\n",
       "        [0.83],\n",
       "        [0.84]],\n",
       "\n",
       "       [[0.04],\n",
       "        [0.05],\n",
       "        [0.06],\n",
       "        [0.07],\n",
       "        [0.08]],\n",
       "\n",
       "       [[0.81],\n",
       "        [0.82],\n",
       "        [0.83],\n",
       "        [0.84],\n",
       "        [0.85]],\n",
       "\n",
       "       [[0.76],\n",
       "        [0.77],\n",
       "        [0.78],\n",
       "        [0.79],\n",
       "        [0.8 ]]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:4,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1206 14:33:37.105715 140544270456576 deprecation_wrapper.py:119] From /home/debo/env_autoencoder/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1206 14:33:39.531853 140544270456576 deprecation_wrapper.py:119] From /home/debo/env_autoencoder/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1206 14:33:39.537022 140544270456576 deprecation_wrapper.py:119] From /home/debo/env_autoencoder/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.add(LSTM((1),batch_input_shape=(None,5,1),return_sequences = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1206 14:33:43.572093 140544270456576 deprecation_wrapper.py:119] From /home/debo/env_autoencoder/local/lib/python2.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mean_absolute_error', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 1)                 12        \n",
      "=================================================================\n",
      "Total params: 12\n",
      "Trainable params: 12\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_model(model, show_shapes=True, to_file='lstm.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/100\n",
      "80/80 [==============================] - 0s 462us/step - loss: 0.4181 - acc: 0.0000e+00 - val_loss: 0.3170 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "80/80 [==============================] - 0s 265us/step - loss: 0.4119 - acc: 0.0000e+00 - val_loss: 0.3115 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.4058 - acc: 0.0000e+00 - val_loss: 0.3059 - val_acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "80/80 [==============================] - 0s 229us/step - loss: 0.3996 - acc: 0.0000e+00 - val_loss: 0.3001 - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "80/80 [==============================] - 0s 230us/step - loss: 0.3934 - acc: 0.0000e+00 - val_loss: 0.2943 - val_acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.3871 - acc: 0.0000e+00 - val_loss: 0.2884 - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.3809 - acc: 0.0000e+00 - val_loss: 0.2824 - val_acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "80/80 [==============================] - 0s 230us/step - loss: 0.3747 - acc: 0.0000e+00 - val_loss: 0.2765 - val_acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "80/80 [==============================] - 0s 235us/step - loss: 0.3685 - acc: 0.0000e+00 - val_loss: 0.2705 - val_acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "80/80 [==============================] - 0s 240us/step - loss: 0.3624 - acc: 0.0000e+00 - val_loss: 0.2646 - val_acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "80/80 [==============================] - 0s 234us/step - loss: 0.3562 - acc: 0.0000e+00 - val_loss: 0.2588 - val_acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "80/80 [==============================] - 0s 230us/step - loss: 0.3504 - acc: 0.0000e+00 - val_loss: 0.2532 - val_acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.3442 - acc: 0.0000e+00 - val_loss: 0.2477 - val_acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "80/80 [==============================] - 0s 234us/step - loss: 0.3384 - acc: 0.0000e+00 - val_loss: 0.2421 - val_acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      "80/80 [==============================] - 0s 237us/step - loss: 0.3324 - acc: 0.0000e+00 - val_loss: 0.2365 - val_acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      "80/80 [==============================] - 0s 234us/step - loss: 0.3265 - acc: 0.0000e+00 - val_loss: 0.2312 - val_acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      "80/80 [==============================] - 0s 233us/step - loss: 0.3210 - acc: 0.0000e+00 - val_loss: 0.2262 - val_acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.3154 - acc: 0.0000e+00 - val_loss: 0.2216 - val_acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "80/80 [==============================] - 0s 240us/step - loss: 0.3096 - acc: 0.0000e+00 - val_loss: 0.2172 - val_acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.2705 - acc: 0.0000e+0 - 0s 239us/step - loss: 0.3044 - acc: 0.0000e+00 - val_loss: 0.2128 - val_acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "80/80 [==============================] - 0s 244us/step - loss: 0.2991 - acc: 0.0000e+00 - val_loss: 0.2090 - val_acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "80/80 [==============================] - 0s 235us/step - loss: 0.2938 - acc: 0.0000e+00 - val_loss: 0.2053 - val_acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "80/80 [==============================] - 0s 231us/step - loss: 0.2886 - acc: 0.0000e+00 - val_loss: 0.2017 - val_acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      "80/80 [==============================] - 0s 242us/step - loss: 0.2838 - acc: 0.0000e+00 - val_loss: 0.1981 - val_acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "80/80 [==============================] - 0s 240us/step - loss: 0.2790 - acc: 0.0000e+00 - val_loss: 0.1946 - val_acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      "80/80 [==============================] - 0s 236us/step - loss: 0.2747 - acc: 0.0000e+00 - val_loss: 0.1914 - val_acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "80/80 [==============================] - 0s 231us/step - loss: 0.2702 - acc: 0.0000e+00 - val_loss: 0.1886 - val_acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "80/80 [==============================] - 0s 239us/step - loss: 0.2658 - acc: 0.0000e+00 - val_loss: 0.1858 - val_acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "80/80 [==============================] - 0s 236us/step - loss: 0.2622 - acc: 0.0000e+00 - val_loss: 0.1831 - val_acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      "80/80 [==============================] - 0s 237us/step - loss: 0.2583 - acc: 0.0000e+00 - val_loss: 0.1805 - val_acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      "80/80 [==============================] - 0s 227us/step - loss: 0.2547 - acc: 0.0000e+00 - val_loss: 0.1779 - val_acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.2516 - acc: 0.0000e+00 - val_loss: 0.1759 - val_acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      "80/80 [==============================] - 0s 230us/step - loss: 0.2481 - acc: 0.0000e+00 - val_loss: 0.1740 - val_acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "80/80 [==============================] - 0s 231us/step - loss: 0.2451 - acc: 0.0000e+00 - val_loss: 0.1722 - val_acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "80/80 [==============================] - 0s 231us/step - loss: 0.2424 - acc: 0.0000e+00 - val_loss: 0.1708 - val_acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "80/80 [==============================] - 0s 232us/step - loss: 0.2394 - acc: 0.0000e+00 - val_loss: 0.1694 - val_acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "80/80 [==============================] - 0s 235us/step - loss: 0.2366 - acc: 0.0000e+00 - val_loss: 0.1681 - val_acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "80/80 [==============================] - 0s 233us/step - loss: 0.2339 - acc: 0.0000e+00 - val_loss: 0.1668 - val_acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "80/80 [==============================] - 0s 229us/step - loss: 0.2317 - acc: 0.0000e+00 - val_loss: 0.1656 - val_acc: 0.0000e+00\n",
      "Epoch 40/100\n",
      "80/80 [==============================] - 0s 241us/step - loss: 0.2291 - acc: 0.0000e+00 - val_loss: 0.1647 - val_acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      "80/80 [==============================] - 0s 234us/step - loss: 0.2269 - acc: 0.0000e+00 - val_loss: 0.1638 - val_acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "80/80 [==============================] - 0s 233us/step - loss: 0.2245 - acc: 0.0000e+00 - val_loss: 0.1629 - val_acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      "80/80 [==============================] - 0s 231us/step - loss: 0.2225 - acc: 0.0000e+00 - val_loss: 0.1621 - val_acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.2204 - acc: 0.0000e+00 - val_loss: 0.1612 - val_acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      "80/80 [==============================] - 0s 246us/step - loss: 0.2185 - acc: 0.0000e+00 - val_loss: 0.1604 - val_acc: 0.0000e+00\n",
      "Epoch 46/100\n",
      "80/80 [==============================] - 0s 229us/step - loss: 0.2166 - acc: 0.0000e+00 - val_loss: 0.1595 - val_acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "80/80 [==============================] - 0s 230us/step - loss: 0.2150 - acc: 0.0000e+00 - val_loss: 0.1587 - val_acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "80/80 [==============================] - 0s 237us/step - loss: 0.2134 - acc: 0.0000e+00 - val_loss: 0.1579 - val_acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "80/80 [==============================] - 0s 235us/step - loss: 0.2117 - acc: 0.0000e+00 - val_loss: 0.1570 - val_acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.2102 - acc: 0.0000e+00 - val_loss: 0.1562 - val_acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      "80/80 [==============================] - 0s 231us/step - loss: 0.2087 - acc: 0.0000e+00 - val_loss: 0.1555 - val_acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      "80/80 [==============================] - 0s 232us/step - loss: 0.2073 - acc: 0.0000e+00 - val_loss: 0.1549 - val_acc: 0.0500\n",
      "Epoch 53/100\n",
      "80/80 [==============================] - 0s 236us/step - loss: 0.2058 - acc: 0.0000e+00 - val_loss: 0.1543 - val_acc: 0.0500\n",
      "Epoch 54/100\n",
      "80/80 [==============================] - 0s 236us/step - loss: 0.2044 - acc: 0.0000e+00 - val_loss: 0.1537 - val_acc: 0.0500\n",
      "Epoch 55/100\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.2030 - acc: 0.0000e+00 - val_loss: 0.1531 - val_acc: 0.0500\n",
      "Epoch 56/100\n",
      "80/80 [==============================] - 0s 233us/step - loss: 0.2016 - acc: 0.0000e+00 - val_loss: 0.1524 - val_acc: 0.0500\n",
      "Epoch 57/100\n",
      "80/80 [==============================] - 0s 242us/step - loss: 0.2003 - acc: 0.0000e+00 - val_loss: 0.1520 - val_acc: 0.0500\n",
      "Epoch 58/100\n",
      "80/80 [==============================] - 0s 243us/step - loss: 0.1989 - acc: 0.0000e+00 - val_loss: 0.1515 - val_acc: 0.0500\n",
      "Epoch 59/100\n",
      "80/80 [==============================] - 0s 239us/step - loss: 0.1976 - acc: 0.0000e+00 - val_loss: 0.1510 - val_acc: 0.0500\n",
      "Epoch 60/100\n",
      "80/80 [==============================] - 0s 236us/step - loss: 0.1961 - acc: 0.0000e+00 - val_loss: 0.1505 - val_acc: 0.0500\n",
      "Epoch 61/100\n",
      "80/80 [==============================] - 0s 240us/step - loss: 0.1949 - acc: 0.0000e+00 - val_loss: 0.1500 - val_acc: 0.0500\n",
      "Epoch 62/100\n",
      "80/80 [==============================] - 0s 234us/step - loss: 0.1936 - acc: 0.0000e+00 - val_loss: 0.1494 - val_acc: 0.0500\n",
      "Epoch 63/100\n",
      "80/80 [==============================] - 0s 235us/step - loss: 0.1924 - acc: 0.0000e+00 - val_loss: 0.1489 - val_acc: 0.0500\n",
      "Epoch 64/100\n",
      "80/80 [==============================] - 0s 239us/step - loss: 0.1911 - acc: 0.0000e+00 - val_loss: 0.1482 - val_acc: 0.0500\n",
      "Epoch 65/100\n",
      "80/80 [==============================] - 0s 240us/step - loss: 0.1899 - acc: 0.0000e+00 - val_loss: 0.1476 - val_acc: 0.0500\n",
      "Epoch 66/100\n",
      "80/80 [==============================] - 0s 244us/step - loss: 0.1887 - acc: 0.0000e+00 - val_loss: 0.1469 - val_acc: 0.0500\n",
      "Epoch 67/100\n",
      "80/80 [==============================] - 0s 244us/step - loss: 0.1875 - acc: 0.0000e+00 - val_loss: 0.1462 - val_acc: 0.0500\n",
      "Epoch 68/100\n",
      "80/80 [==============================] - 0s 242us/step - loss: 0.1863 - acc: 0.0000e+00 - val_loss: 0.1455 - val_acc: 0.0500\n",
      "Epoch 69/100\n",
      "80/80 [==============================] - 0s 234us/step - loss: 0.1851 - acc: 0.0000e+00 - val_loss: 0.1448 - val_acc: 0.0500\n",
      "Epoch 70/100\n",
      "80/80 [==============================] - 0s 230us/step - loss: 0.1839 - acc: 0.0000e+00 - val_loss: 0.1441 - val_acc: 0.0500\n",
      "Epoch 71/100\n",
      "80/80 [==============================] - 0s 232us/step - loss: 0.1827 - acc: 0.0000e+00 - val_loss: 0.1434 - val_acc: 0.0500\n",
      "Epoch 72/100\n",
      "80/80 [==============================] - 0s 230us/step - loss: 0.1815 - acc: 0.0000e+00 - val_loss: 0.1426 - val_acc: 0.0500\n",
      "Epoch 73/100\n",
      "80/80 [==============================] - 0s 233us/step - loss: 0.1803 - acc: 0.0000e+00 - val_loss: 0.1419 - val_acc: 0.0500\n",
      "Epoch 74/100\n",
      "80/80 [==============================] - 0s 226us/step - loss: 0.1792 - acc: 0.0000e+00 - val_loss: 0.1411 - val_acc: 0.0500\n",
      "Epoch 75/100\n",
      "80/80 [==============================] - 0s 230us/step - loss: 0.1780 - acc: 0.0000e+00 - val_loss: 0.1403 - val_acc: 0.0500\n",
      "Epoch 76/100\n",
      "80/80 [==============================] - 0s 229us/step - loss: 0.1769 - acc: 0.0000e+00 - val_loss: 0.1396 - val_acc: 0.0500\n",
      "Epoch 77/100\n",
      "80/80 [==============================] - 0s 230us/step - loss: 0.1756 - acc: 0.0000e+00 - val_loss: 0.1388 - val_acc: 0.0500\n",
      "Epoch 78/100\n",
      "80/80 [==============================] - 0s 227us/step - loss: 0.1745 - acc: 0.0000e+00 - val_loss: 0.1382 - val_acc: 0.0500\n",
      "Epoch 79/100\n",
      "80/80 [==============================] - 0s 236us/step - loss: 0.1733 - acc: 0.0000e+00 - val_loss: 0.1375 - val_acc: 0.0500\n",
      "Epoch 80/100\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.1721 - acc: 0.0000e+00 - val_loss: 0.1369 - val_acc: 0.0500\n",
      "Epoch 81/100\n",
      "80/80 [==============================] - 0s 234us/step - loss: 0.1709 - acc: 0.0000e+00 - val_loss: 0.1362 - val_acc: 0.0500\n",
      "Epoch 82/100\n",
      "80/80 [==============================] - 0s 232us/step - loss: 0.1697 - acc: 0.0000e+00 - val_loss: 0.1355 - val_acc: 0.0500\n",
      "Epoch 83/100\n",
      "80/80 [==============================] - 0s 235us/step - loss: 0.1685 - acc: 0.0000e+00 - val_loss: 0.1348 - val_acc: 0.0500\n",
      "Epoch 84/100\n",
      "80/80 [==============================] - 0s 247us/step - loss: 0.1673 - acc: 0.0000e+00 - val_loss: 0.1342 - val_acc: 0.0500\n",
      "Epoch 85/100\n",
      "80/80 [==============================] - 0s 230us/step - loss: 0.1661 - acc: 0.0000e+00 - val_loss: 0.1335 - val_acc: 0.0500\n",
      "Epoch 86/100\n",
      "80/80 [==============================] - 0s 230us/step - loss: 0.1649 - acc: 0.0000e+00 - val_loss: 0.1328 - val_acc: 0.0500\n",
      "Epoch 87/100\n",
      "80/80 [==============================] - 0s 239us/step - loss: 0.1637 - acc: 0.0000e+00 - val_loss: 0.1321 - val_acc: 0.0500\n",
      "Epoch 88/100\n",
      "80/80 [==============================] - 0s 243us/step - loss: 0.1625 - acc: 0.0000e+00 - val_loss: 0.1314 - val_acc: 0.0500\n",
      "Epoch 89/100\n",
      "80/80 [==============================] - 0s 235us/step - loss: 0.1613 - acc: 0.0000e+00 - val_loss: 0.1307 - val_acc: 0.0500\n",
      "Epoch 90/100\n",
      "80/80 [==============================] - 0s 235us/step - loss: 0.1601 - acc: 0.0000e+00 - val_loss: 0.1300 - val_acc: 0.0500\n",
      "Epoch 91/100\n",
      "80/80 [==============================] - 0s 241us/step - loss: 0.1589 - acc: 0.0000e+00 - val_loss: 0.1293 - val_acc: 0.0500\n",
      "Epoch 92/100\n",
      "80/80 [==============================] - 0s 233us/step - loss: 0.1577 - acc: 0.0000e+00 - val_loss: 0.1287 - val_acc: 0.0500\n",
      "Epoch 93/100\n",
      "80/80 [==============================] - 0s 239us/step - loss: 0.1565 - acc: 0.0000e+00 - val_loss: 0.1280 - val_acc: 0.0500\n",
      "Epoch 94/100\n",
      "80/80 [==============================] - 0s 232us/step - loss: 0.1553 - acc: 0.0000e+00 - val_loss: 0.1273 - val_acc: 0.0500\n",
      "Epoch 95/100\n",
      "80/80 [==============================] - 0s 233us/step - loss: 0.1541 - acc: 0.0000e+00 - val_loss: 0.1267 - val_acc: 0.0500\n",
      "Epoch 96/100\n",
      "80/80 [==============================] - 0s 234us/step - loss: 0.1528 - acc: 0.0000e+00 - val_loss: 0.1260 - val_acc: 0.0500\n",
      "Epoch 97/100\n",
      "80/80 [==============================] - 0s 235us/step - loss: 0.1516 - acc: 0.0000e+00 - val_loss: 0.1253 - val_acc: 0.0500\n",
      "Epoch 98/100\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.1505 - acc: 0.0000e+00 - val_loss: 0.1244 - val_acc: 0.0500\n",
      "Epoch 99/100\n",
      "80/80 [==============================] - 0s 234us/step - loss: 0.1492 - acc: 0.0000e+00 - val_loss: 0.1234 - val_acc: 0.0500\n",
      "Epoch 100/100\n",
      "80/80 [==============================] - 0s 237us/step - loss: 0.1480 - acc: 0.0000e+00 - val_loss: 0.1225 - val_acc: 0.0500\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs = 100, validation_data = (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(range(20),results,c='r')\n",
    "plt.scatter(range(20),y_test,c='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi40LCBodHRwOi8vbWF0cGxvdGxpYi5vcmcv7US4rQAAIABJREFUeJzt3Xl8VfWd//HXJwsJS1iTsIWdLOyLwRUQcCkuA1bFtVa7WR39tdbaaqftTMfWsXV3LLaljks7VSvYhboxLiAqooR9SyBskggkbGFNQpLP7497YSIjcoEk5+be9/PxyIN7tns/53F4vO893+/3nGPujoiIxIeEoAsQEZGmo9AXEYkjCn0RkTii0BcRiSMKfRGROKLQFxGJIwp9EZE4otAXEYkjCn0RkTiSFHQBR0tPT/fevXsHXYaISLOycOHC7e6ecbz1oi70e/fuTUFBQdBliIg0K2a2KZL11LwjIhJHFPoiInFEoS8iEkcU+iIicUShLyISRxT6IiJxRKEvIhJHYib0Kw/V8svXC9m880DQpYiIRK2YCf0d+6v57/mbuPvlZdTV6bm/IiKfJ2ZCv3v7lvzkkgHMW7eD//4oogvTRETiTsyEPsDVo3owNieD+18rZNOO/UGXIyISdWIq9M2MX10xhKRE4wfT1cwjInK0mAp9gK7tWvKvlw7k4407efqDDUGXIyISVWIu9AGuPC2L8wdk8sCsItZu2xt0OSIiUSMmQ9/MuP/yobRJSeLOl5ZyqLYu6JJERKJCTIY+QEZaCvddNpjlpRU88U5x0OWIiESFmA19gIuGdOXyEd2ZOruYJZt3B12OiEjgYjr0AX42eRCd01K486UlVB6qDbocEZFARRT6ZjbRzIrMrNjM7vmC9a4wMzez/HrzfhTersjMvtQQRZ+ItqnJPHDlMNaX7+fBWUVN/fEiIlHluKFvZonAVOAiYCBwrZkN/Jz10oDvAh/VmzcQuAYYBEwEngy/X5ManZ3OV8/qxdMfbGD++h1N/fEiIlEjkl/6pwPF7r7e3auBF4HJn7Pez4FfAZX15k0GXnT3KnffABSH36/J3XNRHj07tuKu6UvZV1UTRAkiIoGLJPS7A5vrTZeE5x1hZiOBHu7+6oluG97+ZjMrMLOC8vLyiAo/Ua1aJPHwlGGU7j7Ifa+ubpTPEBGJdqfckWtmCcAjwPdP9j3cfZq757t7fkZGxqmWdEz5vTty85i+vPDxJ8xd0zhfLiIi0SyS0C8FetSbzgrPOywNGAzMMbONwJnAzHBn7vG2bXLfuyCH/pltuPvlZeypPBRkKSIiTS6S0F8AZJtZHzNrQahjdubhhe5e4e7p7t7b3XsD84FJ7l4QXu8aM0sxsz5ANvBxg+/FCUhNTuThKcMo21vFL15ZFWQpIiJN7rih7+41wO3ALGA18JK7rzSze81s0nG2XQm8BKwC3gBuc/fAB8sP69GeW87ty0sFJcwuLAu6HBGRJmPu0XX74fz8fC8oKGj0z6mqqWXSEx+w+2A1/3PHubRrldzonyki0ljMbKG75x9vvZi/IvdYUpISefiqYezYV83P/rEy6HJERJpE3IY+wODu7bhtfH/+uriUWSu3Bl2OiEiji+vQB7h9Qn8GdWvLj/+6nJ37q4MuR0SkUcV96CcnJvDwVcOoOHiIn/59RdDliIg0qrgPfYC8Lm254/wcXl22hVeWfRp0OSIijUahH/btsX0ZltWOn/5tBeV7q4IuR0SkUSj0w5ISE3hoyjD2V9fyk78tJ9qGsoqINASFfj3ZndP4/gU5zFq5jZlL1cwjIrFHoX+Ub47py8ie7fnXv69k257K428gItKMKPSPkphgPDRlGFU1tfxwxjI184hITFHof46+GW340UUDeHdNOS98vPn4G4iINBMK/WO44cxenNO/E794dRWf7DgQdDkiIg1CoX8MCQnGg1cOI9GM709fQm2dmnlEpPlT6H+Bbu1b8m+TBrFg4y6enbcx6HJERE6ZQv84rhjZnQl5mTw4q5AN2/cHXY6IyClR6B+HmXH/5UNokZjAD6YvVTOPiDRrCv0IdG6bys8mDaJg0y6e+WBD0OWIiJw0hX6EvjyiO+cPyOTBWUUUl+0LuhwRkZOi0I+QmfEflw+hVYtEvvfnJRyqrQu6JBGRE6bQPwGZaancf/kQlpdW8MQ7xUGXIyJywhT6J2ji4K5cPrI7U2cXs+iTXUGXIyJyQhT6J+FnkwbRpW0qd/55CQeqa4IuR0QkYgr9k9A2NZmHpgxj444D/Or1wqDLERGJmEL/JJ3VrxM3nd2b5z7cxLzi7UGXIyISEYX+Kbh7Yh590lvzgxnL2Ft5KOhyRESOS6F/Clq2SOShKUPZUnGQ+15dHXQ5IiLHpdA/Raf16si3xvblxQWbeXPVtqDLERH5QhGFvplNNLMiMys2s3s+Z/ktZrbczJaY2ftmNjA8v7eZHQzPX2Jmv23oHYgGd16Qw8CubfnhjKVsrdAjFkUkeh039M0sEZgKXAQMBK49HOr1PO/uQ9x9OPAA8Ei9ZevcfXj475aGKjyapCQl8sR1I6g8VMcdf16sm7KJSNSK5Jf+6UCxu69392rgRWBy/RXcfU+9ydZA3KVev4w2/PvkQcxfv5PfzNHVuiISnSIJ/e5A/QfFloTnfYaZ3WZm6wj90v9OvUV9zGyxmb1rZmNOqdooN+W0LCYN68ajb61lsa7WFZEo1GAdue4+1d37AXcDPwnP3gL0dPcRwJ3A82bW9uhtzexmMysws4Ly8vKGKqnJmRm/+PJgOqel8P2XlnKwujbokkREPiOS0C8FetSbzgrPO5YXgcsA3L3K3XeEXy8E1gE5R2/g7tPcPd/d8zMyMiKtPSq1TU3mgSuHsX77fh6cVRR0OSIinxFJ6C8Ass2sj5m1AK4BZtZfwcyy601eAqwNz88IdwRjZn2BbGB9QxQezUZnp3PDmb14Zt4G5q/fEXQ5IiJHHDf03b0GuB2YBawGXnL3lWZ2r5lNCq92u5mtNLMlhJpxbgzPHwssC8+fAdzi7jsbfC+i0D0X5dGzYyt+MGMp+6p0UzYRiQ7mHl0DbfLz872goCDoMhrEgo07uep3HzLltCweuHJY0OWISAwzs4Xunn+89XRFbiMa1bsj/zyuHy8VlPDa8i1BlyMiotBvbHecn8OwHu255+VlfLr7YNDliEicU+g3suTEBB6/eji1dc4df16iq3VFJFAK/SbQO701/z55MB9v2Mlv310XdDkiEscU+k3kipHduWRoVx59cw0rSiuCLkdE4pRCv4mYGfddNpj0Nil898XFulpXRAKh0G9C7Vu14OGrhrGufD/3v66HrohI01PoN7Fz+qfzzdF9+MOHm5hdWBZ0OSISZxT6AbjrS7nkdUnjBzOWUr63KuhyRCSOKPQDkJqcyOPXjGBPZQ0/mLGUaLsqWkRil0I/ILld0vjxxQOYU1TOs/M2Bl2OiMQJhX6AvnpWLybkZXL/64Ws3rLn+BuIiJwihX6AzIwHrhxK29Rkbnt+ke7GKSKNTqEfsPQ2KTxx7Qg2bt/P3S8vU/u+iDQqhX4UOKtfJ+76Ui6vLtvCHz7cFHQ5IhLDFPpR4pax/TgvL5NfvLpKD1UXkUaj0I8SCQnGI1cNp3PbVG5/fjEVBw4FXZKIxCCFfhRp1yqZX183krK9ldyl8fsi0ggU+lFmeI/23D0xjzdXbdP4fRFpcAr9KPSN0X04f0Am//HaapaV7A66HBGJIQr9KGRmPDRlGBltUvh/Lyxmb6Xa90WkYSj0o1T7Vi14/NoRbN55gH/9+8qgyxGRGKHQj2Kjenfku+fl8NfFpfxlUUnQ5YhIDFDoR7nbJ/Tn9D4d+enfVrBh+/6gyxGRZk6hH+USE4zHrh5OUmICt/1pkR6zKCKnRKHfDHRr35LHrh7O6q17+KHuzyMip0Ch30yMz8vkrgtz+cfST/nd3PVBlyMizZRCvxn553H9uGRIV371RiFzivR8XRE5cRGFvplNNLMiMys2s3s+Z/ktZrbczJaY2ftmNrDesh+Ftysysy81ZPHxxsx4cMpQcjun8Z0XFrNphzp2ReTEHDf0zSwRmApcBAwErq0f6mHPu/sQdx8OPAA8Et52IHANMAiYCDwZfj85Sa1aJDHthnzMjG//cSEHqvXgFRGJXCS/9E8Hit19vbtXAy8Ck+uv4O71n/XXGjjc0zgZeNHdq9x9A1Acfj85BT07teKJa0ewZtte7n55uTp2RSRikYR+d2BzvemS8LzPMLPbzGwdoV/63zmRbeXEjc3J4K4vhTp2n3pvQ9DliEgz0WAdue4+1d37AXcDPzmRbc3sZjMrMLOC8vLyhiop5t16bj8uGtyF+19fzbzi7UGXIyLNQCShXwr0qDedFZ53LC8Cl53Itu4+zd3z3T0/IyMjgpIEDnfsDqNfRhtue34Rm3ceCLokEYlykYT+AiDbzPqYWQtCHbMz669gZtn1Ji8B1oZfzwSuMbMUM+sDZAMfn3rZcliblCSmfTWfmjrn239cqCt2ReQLHTf03b0GuB2YBawGXnL3lWZ2r5lNCq92u5mtNLMlwJ3AjeFtVwIvAauAN4Db3F2p1MD6pLfm8WtCV+z+6C+6YldEjs2iLSDy8/O9oKAg6DKapSfeXsvDb67hJ5cM4Jtj+gZdjog0ITNb6O75x1tPV+TGkNvG9+dLgzpz/+uF6tgVkc+l0I8hCQnGw1cNp296a3XsisjnUujHmKM7dvdX6YpdEflfCv0Y1Ce9Nf957QgKt+7hOy8spqa2LuiSRCRKKPRj1PjcTH5+2WDeLizj32au1IgeEQEgKegCpPFcf0YvSnYd5Ddz1pHVoRW3jusXdEkiEjCFfoz7wYW5lO46yK/eKKRb+1QmD9etj0TimUI/xiUkhO7Bv21PJXdNX0pmWipn9esUdFkiEhC16ceBlKREpt2QT+9Orbn5jwWs2bY36JJEJCAK/TjRrlUyz3xtFKnJidz09Md8uvtg0CWJSAAU+nEkq0MrnrlpFHsra7j29/PZWlEZdEki0sQU+nFmcPd2PPeN09m+t4rrnppP2V4Fv0g8UejHoZE9O/Ds109ny+5Krv/9R+zYVxV0SSLSRBT6cWpU7448fdMoPtl5gK89u4B9ul2DSFxQ6Mexs/p14snrR7Ly0z3c/IcCqmr0qAORWKfQj3PnDejMg1cOZd66HXz3hSXU1ul2DSKxTKEvXD4yi59eOpA3Vm7lhzOWUafgF4lZuiJXAPjG6D7sq6zh0bfWkJxo/MeXh5CQYEGXJSINTKEvR3znvP4cqq3j17OLSU5M4N7JgzBT8IvEEoW+HGFmfP/CHKpr65g2dz3VNXX84suDSU5UK6BIrFDoy2eYGT+6KI+UpASeeKeYTysO8uT1I0lLTQ66NBFpAPoJJ/9H6Bd/Lg9cMZQP1+1gym8/1L16RGKEQl+O6apRPXj2a6dTuusgV/5mHuvK9wVdkoicIoW+fKHR2em8cPOZVNfWcdVvP2RFaUXQJYnIKVDoy3EN7t6O6becTWpyItdMm8+8dduDLklETpJCXyLSJ701M249i67tUrnx6Y+ZsbAk6JJE5CQo9CViXdu1ZMatZ3N6n47cNX0pD80q0tW7Is2MQl9OSLuWyTz7tdO5Or8Hv55dzK1/WkjFwUNBlyUiEYoo9M1sopkVmVmxmd3zOcvvNLNVZrbMzN42s171ltWa2ZLw38yGLF6CkZyYwC+vGMJPLhnA26vLuPjx91j0ya6gyxKRCBw39M0sEZgKXAQMBK41s4FHrbYYyHf3ocAM4IF6yw66+/Dw36QGqlsCZmZ8c0xfpt9yFmZw1W8/5Pdz1+Ou5h6RaBbJL/3TgWJ3X+/u1cCLwOT6K7j7bHc/EJ6cD2Q1bJkSrUb07MCr3xnDBQM7c99rq7lr+jLdl18kikUS+t2BzfWmS8LzjuUbwOv1plPNrMDM5pvZZZ+3gZndHF6noLy8PIKSJJq0a5nMk9eP5Hvn5/DyohKunTaf8r16BKNINGrQjlwz+wqQDzxYb3Yvd88HrgMeM7N+R2/n7tPcPd/d8zMyMhqyJGkiZsZ3z89m6nUjWbVlD5c+8R4fFGs8v0i0iST0S4Ee9aazwvM+w8zOB34MTHL3Iz/z3L00/O96YA4w4hTqlSh3ydCuvHzr2bROSeIr//UR97+2muqauqDLEpGwSEJ/AZBtZn3MrAVwDfCZUThmNgL4HaHAL6s3v4OZpYRfpwPnAKsaqniJToO6teOV/zeaa0b15Hdz1/PlJz9g1ad7gi5LRIgg9N29BrgdmAWsBl5y95Vmdq+ZHR6N8yDQBph+1NDMAUCBmS0FZgO/dHeFfhxo1SKJ+y8fwu9uOI1teyqZ9Ov3eeR/itTJKxIwi7Yhdvn5+V5QUBB0GdKAdu2v5uevrOIvi0vJ7ZzG49cOJ69L26DLEokpZrYw3H/6hXRFrjS6Dq1b8MjVw3n6pnx27K9m0q8/4On3N+gWDiIBUOhLk5mQ15lZd4xhTP907n1lFTc+87EeziLSxBT60qQ6tUnhqRvz+fllgynYuIsLH53L8x99oit5RZqIQl+anJlxw5m9mHXHWIZ0b8e//HU51z/1EZt3Hjj+xiJyShT6EpienVrx/LfO4L4vD2ZZSQUXPjqXZz9QW79IY1LoS6DMjOvP6MWs741lVJ+O/Owfq7h62ocs2bw76NJEYpJCX6JC9/Ytee5ro3jwyqEUl+3jsqkf8M3nCli9RRd1iTQkhb5EDTNjSn4P3rt7AnddmMNHG3Zw8X++x7/8dTkVB/SgFpGGoNCXqNMmJYnbJ2Tz/g8n8PVz+vDnBZuZ8PAc/rKoRKN8RE6RQl+iVrtWyfz00oH84/bR9OzUijtfWsplUz9gnu7eKXLSFPoS9QZ2a8vLt5zNg1cOpXxvFdc99RFfffpj3cRN5CTo3jvSrFQequW/52/i17OLqTh4iC+P6M5dF+bSrX3LoEsTCVSk995R6EuzVHHwEE/OLuaZeRsx4Ctn9uLbY/uS2TY16NJEAqHQl7hQsusAj765lr8tKSUxwbg6vwe3juunX/4SdxT6Elc+2XGA37xbzIyFJQBcPaoHt43vT9d2Cn+JDwp9iUuluw8ydXYxLy3YTIIZU/Kz+NaYvvRObx10aSKNSqEvcW3zzgM8OaeYlxeWcqiujomDuvCtsX0Z2bND0KWJNAqFvghQtreS5+Zt5I8fbmJPZQ3DerTn6+f05uIhXUlO1IhliR0KfZF69lfV8PKiEp79YCPrt+8nIy2FKadlcc2onvTs1Cro8kROmUJf5HPU1TnvrinnTx9t4p3CMuoczu7XiSn5WUwc1JWWLRKDLlHkpCj0RY5jS8VBpheUMH3hZjbvPEiblCQuHdqVq0f1YHiP9phZ0CWKREyhLxKhujpnwcadTF9YwmvLt3CgupbczmlcPaoHk4d3o1OblKBLFDkuhb7ISdhbeYh/LN3Ciws+YVlJBUkJxrjcTC4f2Z0JeZmkJqv5R6KTQl/kFBVt3ctfFpXw18WllO2tok1KEhcO7Mw/De/G6P7pGv0jUUWhL9JAauucD9ftYObSUl5fsZW9lTW0b5XMRYO78E9Du3FG304kJqj9X4Kl0BdpBFU1tcxds51Xln3Km6u2caC6li5tU5k8ohuXj8git0ta0CVKnFLoizSyg9W1vF24jb8uKmXOmnJq65yczm24eEhXLh3alf6Z+gKQptOgoW9mE4HHgUTgKXf/5VHL7wS+CdQA5cDX3X1TeNmNwE/Cq/7C3Z/7os9S6EtztH1fFa8s/ZTXlm9lwaaduEN2ZugL4OIhXcnp3EZDQKVRNVjom1kisAa4ACgBFgDXuvuqeuuMBz5y9wNmdiswzt2vNrOOQAGQDziwEDjN3Xcd6/MU+tLcbdtTyevLt/D6iq18vDH0BdAvozUXD+nKRYO7MqBrmr4ApMFFGvpJEbzX6UCxu68Pv/GLwGTgSOi7++x6688HvhJ+/SXgTXffGd72TWAi8EIkOyHSHHVum8pN5/ThpnP6ULa3klkrtvL6iq1MnV3ME+8U06tTKy4c2JkLB3VhZM8O6gSWJhVJ6HcHNtebLgHO+IL1vwG8/gXbdj+RAkWas8y0VG44qzc3nNWbHfuqmLVyG/+zaivPztvI79/bQEZaChcP7sKlw7pxWs8OJOgLQBpZJKEfMTP7CqGmnHNPcLubgZsBevbs2ZAliUSNTm1SuO6Mnlx3Rk/2Vh7incIyXlu+hRcWbOa5DzeRmZbCeQM6c+GgzpzdrxMpSboQTBpeJKFfCvSoN50VnvcZZnY+8GPgXHevqrftuKO2nXP0tu4+DZgGoTb9CGoSadbSUpOZPLw7k4d3Z19VDW+tCp0BzFxSygsff0JaShIXDOzMJUO7Mjo7XV8A0mAi6chNItSRex6hEF8AXOfuK+utMwKYAUx097X15nck1Hk7MjxrEaGO3J3H+jx15Eo8qzxUy4frdvD6ii28sWIreypraJOSxJjsdCbkZTI+L5N03QtIPkdDD9m8GHiM0JDNp939PjO7Fyhw95lm9hYwBNgS3uQTd58U3vbrwL+E59/n7s980Wcp9EVCqmvqeL+4nDdXbePt1WWU7a3CDIb3aM95eZmcN6AzeV00EkhCdHGWSAxxd1aU7uGdwjLeKdzG0pIKALq2S2V8Xibn5WVyTv903RAujin0RWJY2Z5K5hSV83bhNt5fu5391bW0TE5kbE46FwzswrjcDDUDxRmFvkicqKqpZf76nby5aitvrSpj655KAIZmtWNcTgbj8jIZltVe1wPEOIW+SBw63Aw0p6iMOWvKWfzJLuocOrRK5tycDMbnZTI2O4MOrVsEXao0MIW+iLD7QDVz125nTmHoS2Dn/uojncHjczMZl5vB4G7tdFFYDFDoi8hn1NU5y0ormFNUxuzCMpaVVuAO6W1aMDYng3NzMnQW0Iwp9EXkC+3YV8XcteXMLixn7tpydh84RILBkKz2nJudzticDIb3aE+SnhDWLCj0RSRitXXOspLdzCkKfQEs3bybOoe2qUmMyclgfG4m5+ZkkJGmEUHRSqEvIiet4sAhPli3PdQUVFRO+d7QnVUOjwg6NzeTYVntdBYQRRT6ItIg6uqcVVvCI4KKylkUHhGUlprEOf3SGZOTztjsDHp0bBV0qXFNoS8ijWL3gWrmrdvB3DXlzF1TzqcVoesCendqxZjsDMbnZXBW33RattDVwU1JoS8ijc7dWb99P++tKee9tdv5cP0ODlTXkpKUwBl9OzGmfzqjs9PJ7ZymYaGNTKEvIk2uqqaWjzfs5J3CMuauKWdd+X4A0tukMC431CE8JiedtqnJAVcaexrycYkiIhFJSUpkTHYGY7IzANhScZAPinfw7prQ3UJnLCwhMcEY3qM9o/unMzYnnWFZGhbalPRLX0SaRE1tHYs372ZOURnvr91+5OKwdi2TGZuTwbicDMZqWOhJU/OOiES13Qeqeb94O3OKyplTVM72faFhoYO7tz1ydfDIXh1I1llARBT6ItJsHB4W+u6act4tKmfhJ7uorXNat0jkrH7pjM8L9Qd0a98y6FKjlkJfRJqtPZWHmFe8g7lrQ18CpbsPApDXJY0JeZmcNyCT4T066HbR9Sj0RSQmuDvFZfvCTw0ro2BT6CygQ6tkxmRnMDo7nTHZ6XRtF99nAQp9EYlJFQcPMXdNOe8UlvHe2u1H+gJyO6cxYUDo0ZEjesbfWYBCX0RinrtTuHUv74XvFrpg405q6px2LZM5p38nxmaHRgTFQ1+AQl9E4k7FwUO8F+4HeG/t9iOPjszrksa43EzG58buiCCFvojENXdnbdk+5hSF+wI27qKmzmmTksRZ/Tpxbk4GE/JiZ0SQQl9EpJ76I4LmrimnZNdnRwSdm9O8zwIU+iIix+DurCsPjQh6e/X/jghqk5LE2f06MT4v9Pzg5jQiSKEvIhKh0FnAdt5ds513i8qO3C46r0sa5+ZmMC4nk/ze0X0WoNAXETkJh/sCZheGHhpTsGknh2pDZwGj+//v1cGZbVODLvUzFPoiIg1gX1UNHxy5R1AZW8JnAYO7t2V8bibj8zIZltU+8OsCFPoiIg3M3Snatpd3CsuYXVjGwk2hR0d2bN2Cc3MyGJcbulFch9Ytmry2Bg19M5sIPA4kAk+5+y+PWj4WeAwYClzj7jPqLasFlocnP3H3SV/0WQp9EWkudh+oPnKTuDlrytm5v5oEgxE9OzA+N4NxuZkM7Nq2SZ4a1mChb2aJwBrgAqAEWABc6+6r6q3TG2gL3AXMPCr097l7m0gLV+iLSHNUW+csK9nNnKJyZheVsaykAgg9NezwWcCY7HTat2qcs4CGfHLW6UCxu68Pv/GLwGTgSOi7+8bwsrqTqlZEpJlLTDBG9OzAiJ4d+N4FOZTvrWLumtAZwFurt/HyohISDIb1aM+4nEzG52UwuFu7Jn92cCSh3x3YXG+6BDjjBD4j1cwKgBrgl+7+t6NXMLObgZsBevbseQJvLSISnTLSUrjitCyuOC2L2jpnacnuI81Aj729hkffWkN6mxTG52Zw3oBMRmdn0Cal8Z9g2xTPyO3l7qVm1hd4x8yWu/u6+iu4+zRgGoSad5qgJhGRJpOYYIzs2YGR4bOAHfuqeDd8p9BZK7cyfWEJyYnGhYO6MPW6kY1aSyShXwr0qDedFZ4XEXcvDf+73szmACOAdV+4kYhIDOvUJoXLR2Zx+cgsDtXWsXDTLmYXljXJsM9IQn8BkG1mfQiF/TXAdZG8uZl1AA64e5WZpQPnAA+cbLEiIrEmOTGBM/t24sy+nZrk8457TbG71wC3A7OA1cBL7r7SzO41s0kAZjbKzEqAKcDvzGxlePMBQIGZLQVmE2rTX/V/P0VERJqCLs4SEYkBkQ7ZjN67B4mISINT6IuIxBGFvohIHFHoi4jEEYW+iEgcUeiLiMSRqBuyaWblwKZTeIt0YHsDldNcxOM+Q3zudzzuM8Tnfp/oPvdy94zjrRR1oX+qzKwgkrGqsSQe9xnic7/jcZ8hPve7sfZZzTsiInFEoS8iEkdiMfSnBV1AAOJxnyE+9zse9xnic78bZZ9jrk1fRESOLRZ/6YuIyDHETOjl1NJNAAADf0lEQVSb2UQzKzKzYjO7J+h6GouZ9TCz2Wa2ysxWmtl3w/M7mtmbZrY2/G+HoGttaGaWaGaLzeyV8HQfM/sofMz/bGaN88TpAJlZezObYWaFZrbazM6K9WNtZt8L/99eYWYvmFlqLB5rM3vazMrMbEW9eZ97bC3kP8P7v8zMTvrxWjER+maWCEwFLgIGAtea2cBgq2o0NcD33X0gcCZwW3hf7wHedvds4O3wdKz5LqFnOhz2K+BRd+8P7AK+EUhVjetx4A13zwOGEdr/mD3WZtYd+A6Q7+6DgURCD26KxWP9LDDxqHnHOrYXAdnhv5uB35zsh8ZE6AOnA8Xuvt7dq4EXgckB19Qo3H2Luy8Kv95LKAS6E9rf58KrPQdcFkyFjcPMsoBLgKfC0wZMAGaEV4nFfW4HjAX+C8Ddq919NzF+rAk90a+lmSUBrYAtxOCxdve5wM6jZh/r2E4G/uAh84H2Ztb1ZD43VkK/O7C53nRJeF5MM7PehJ45/BHQ2d23hBdtBToHVFZjeQz4IVAXnu4E7A4/2Q1i85j3AcqBZ8LNWk+ZWWti+FiHn6n9EPAJobCvABYS+8f6sGMd2wbLuFgJ/bhjZm2Al4E73H1P/WUeGpIVM8OyzOxSoMzdFwZdSxNLAkYCv3H3EcB+jmrKicFj3YHQr9o+QDegNf+3CSQuNNaxjZXQLwV61JvOCs+LSWaWTCjw/+TufwnP3nb4dC/8b1lQ9TWCc4BJZraRUNPdBEJt3e3DTQAQm8e8BChx94/C0zMIfQnE8rE+H9jg7uXufgj4C6HjH+vH+rBjHdsGy7hYCf0FQHa4h78FoY6fmQHX1CjCbdn/Bax290fqLZoJ3Bh+fSPw96aurbG4+4/cPcvdexM6tu+4+/XAbODK8Goxtc8A7r4V2GxmueFZ5wGriOFjTahZ50wzaxX+v354n2P6WNdzrGM7E/hqeBTPmUBFvWagE+PuMfEHXAysAdYBPw66nkbcz9GETvmWAUvCfxcTauN+G1gLvAV0DLrWRtr/ccAr4dd9gY+BYmA6kBJ0fY2wv8OBgvDx/hvQIdaPNfDvQCGwAvgjkBKLxxp4gVC/xSFCZ3XfONaxBYzQCMV1wHJCo5tO6nN1Ra6ISByJleYdERGJgEJfRCSOKPRFROKIQl9EJI4o9EVE4ohCX0Qkjij0RUTiiEJfRCSO/H8l7L7T3tNa8gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(LSTM((1),batch_input_shape=(None,5,1),return_sequences = True))\n",
    "model2.add(LSTM((1),return_sequences = False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 5, 1)              12        \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 1)                 12        \n",
      "=================================================================\n",
      "Total params: 24\n",
      "Trainable params: 24\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_model(model2, show_shapes=True, to_file='lstm2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2.compile(loss='mean_absolute_error', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/200\n",
      "80/80 [==============================] - 0s 634us/step - loss: 0.2028 - acc: 0.0000e+00 - val_loss: 0.2102 - val_acc: 0.0500\n",
      "Epoch 2/200\n",
      "80/80 [==============================] - 0s 322us/step - loss: 0.2021 - acc: 0.0000e+00 - val_loss: 0.2102 - val_acc: 0.0500\n",
      "Epoch 3/200\n",
      "80/80 [==============================] - 0s 315us/step - loss: 0.2014 - acc: 0.0000e+00 - val_loss: 0.2103 - val_acc: 0.0500\n",
      "Epoch 4/200\n",
      "80/80 [==============================] - 0s 365us/step - loss: 0.2007 - acc: 0.0000e+00 - val_loss: 0.2104 - val_acc: 0.0500\n",
      "Epoch 5/200\n",
      "80/80 [==============================] - 0s 349us/step - loss: 0.2000 - acc: 0.0000e+00 - val_loss: 0.2103 - val_acc: 0.0500\n",
      "Epoch 6/200\n",
      "80/80 [==============================] - 0s 352us/step - loss: 0.1993 - acc: 0.0000e+00 - val_loss: 0.2102 - val_acc: 0.0500\n",
      "Epoch 7/200\n",
      "80/80 [==============================] - 0s 346us/step - loss: 0.1986 - acc: 0.0000e+00 - val_loss: 0.2099 - val_acc: 0.0500\n",
      "Epoch 8/200\n",
      "80/80 [==============================] - 0s 359us/step - loss: 0.1978 - acc: 0.0000e+00 - val_loss: 0.2094 - val_acc: 0.0500\n",
      "Epoch 9/200\n",
      "80/80 [==============================] - 0s 342us/step - loss: 0.1970 - acc: 0.0000e+00 - val_loss: 0.2090 - val_acc: 0.0500\n",
      "Epoch 10/200\n",
      "80/80 [==============================] - 0s 346us/step - loss: 0.1963 - acc: 0.0000e+00 - val_loss: 0.2087 - val_acc: 0.0500\n",
      "Epoch 11/200\n",
      "80/80 [==============================] - 0s 353us/step - loss: 0.1955 - acc: 0.0000e+00 - val_loss: 0.2082 - val_acc: 0.0500\n",
      "Epoch 12/200\n",
      "80/80 [==============================] - 0s 348us/step - loss: 0.1948 - acc: 0.0000e+00 - val_loss: 0.2080 - val_acc: 0.0500\n",
      "Epoch 13/200\n",
      "80/80 [==============================] - 0s 342us/step - loss: 0.1940 - acc: 0.0000e+00 - val_loss: 0.2078 - val_acc: 0.0500\n",
      "Epoch 14/200\n",
      "80/80 [==============================] - 0s 343us/step - loss: 0.1932 - acc: 0.0000e+00 - val_loss: 0.2074 - val_acc: 0.0500\n",
      "Epoch 15/200\n",
      "80/80 [==============================] - 0s 346us/step - loss: 0.1924 - acc: 0.0000e+00 - val_loss: 0.2068 - val_acc: 0.0500\n",
      "Epoch 16/200\n",
      "80/80 [==============================] - 0s 353us/step - loss: 0.1916 - acc: 0.0000e+00 - val_loss: 0.2064 - val_acc: 0.0500\n",
      "Epoch 17/200\n",
      "80/80 [==============================] - 0s 365us/step - loss: 0.1907 - acc: 0.0000e+00 - val_loss: 0.2057 - val_acc: 0.0500\n",
      "Epoch 18/200\n",
      "80/80 [==============================] - 0s 347us/step - loss: 0.1899 - acc: 0.0000e+00 - val_loss: 0.2050 - val_acc: 0.0500\n",
      "Epoch 19/200\n",
      "80/80 [==============================] - 0s 347us/step - loss: 0.1890 - acc: 0.0000e+00 - val_loss: 0.2044 - val_acc: 0.0500\n",
      "Epoch 20/200\n",
      "80/80 [==============================] - 0s 348us/step - loss: 0.1881 - acc: 0.0000e+00 - val_loss: 0.2032 - val_acc: 0.0500\n",
      "Epoch 21/200\n",
      "80/80 [==============================] - 0s 354us/step - loss: 0.1873 - acc: 0.0000e+00 - val_loss: 0.2020 - val_acc: 0.0500\n",
      "Epoch 22/200\n",
      "80/80 [==============================] - 0s 350us/step - loss: 0.1864 - acc: 0.0000e+00 - val_loss: 0.2011 - val_acc: 0.0500\n",
      "Epoch 23/200\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.1854 - acc: 0.0000e+00 - val_loss: 0.2001 - val_acc: 0.0500\n",
      "Epoch 24/200\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.1845 - acc: 0.0000e+00 - val_loss: 0.1992 - val_acc: 0.0500\n",
      "Epoch 25/200\n",
      "80/80 [==============================] - 0s 355us/step - loss: 0.1836 - acc: 0.0000e+00 - val_loss: 0.1986 - val_acc: 0.0500\n",
      "Epoch 26/200\n",
      "80/80 [==============================] - 0s 348us/step - loss: 0.1826 - acc: 0.0000e+00 - val_loss: 0.1979 - val_acc: 0.0500\n",
      "Epoch 27/200\n",
      "80/80 [==============================] - 0s 355us/step - loss: 0.1816 - acc: 0.0000e+00 - val_loss: 0.1964 - val_acc: 0.0500\n",
      "Epoch 28/200\n",
      "80/80 [==============================] - 0s 342us/step - loss: 0.1806 - acc: 0.0000e+00 - val_loss: 0.1950 - val_acc: 0.0500\n",
      "Epoch 29/200\n",
      "80/80 [==============================] - 0s 346us/step - loss: 0.1796 - acc: 0.0000e+00 - val_loss: 0.1944 - val_acc: 0.0500\n",
      "Epoch 30/200\n",
      "80/80 [==============================] - 0s 353us/step - loss: 0.1785 - acc: 0.0000e+00 - val_loss: 0.1937 - val_acc: 0.0500\n",
      "Epoch 31/200\n",
      "80/80 [==============================] - 0s 350us/step - loss: 0.1774 - acc: 0.0000e+00 - val_loss: 0.1933 - val_acc: 0.0500\n",
      "Epoch 32/200\n",
      "80/80 [==============================] - 0s 361us/step - loss: 0.1763 - acc: 0.0000e+00 - val_loss: 0.1931 - val_acc: 0.0500\n",
      "Epoch 33/200\n",
      "80/80 [==============================] - 0s 347us/step - loss: 0.1753 - acc: 0.0000e+00 - val_loss: 0.1927 - val_acc: 0.0500\n",
      "Epoch 34/200\n",
      "80/80 [==============================] - 0s 356us/step - loss: 0.1742 - acc: 0.0000e+00 - val_loss: 0.1917 - val_acc: 0.0500\n",
      "Epoch 35/200\n",
      "80/80 [==============================] - 0s 339us/step - loss: 0.1730 - acc: 0.0000e+00 - val_loss: 0.1907 - val_acc: 0.0500\n",
      "Epoch 36/200\n",
      "80/80 [==============================] - 0s 345us/step - loss: 0.1719 - acc: 0.0000e+00 - val_loss: 0.1897 - val_acc: 0.0500\n",
      "Epoch 37/200\n",
      "80/80 [==============================] - 0s 350us/step - loss: 0.1707 - acc: 0.0000e+00 - val_loss: 0.1884 - val_acc: 0.0500\n",
      "Epoch 38/200\n",
      "80/80 [==============================] - 0s 347us/step - loss: 0.1695 - acc: 0.0000e+00 - val_loss: 0.1871 - val_acc: 0.0500\n",
      "Epoch 39/200\n",
      "80/80 [==============================] - 0s 345us/step - loss: 0.1683 - acc: 0.0000e+00 - val_loss: 0.1855 - val_acc: 0.0500\n",
      "Epoch 40/200\n",
      "80/80 [==============================] - 0s 358us/step - loss: 0.1670 - acc: 0.0000e+00 - val_loss: 0.1838 - val_acc: 0.0500\n",
      "Epoch 41/200\n",
      "80/80 [==============================] - 0s 353us/step - loss: 0.1658 - acc: 0.0000e+00 - val_loss: 0.1821 - val_acc: 0.0500\n",
      "Epoch 42/200\n",
      "80/80 [==============================] - 0s 343us/step - loss: 0.1644 - acc: 0.0000e+00 - val_loss: 0.1805 - val_acc: 0.0500\n",
      "Epoch 43/200\n",
      "80/80 [==============================] - 0s 346us/step - loss: 0.1631 - acc: 0.0000e+00 - val_loss: 0.1789 - val_acc: 0.0500\n",
      "Epoch 44/200\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.1617 - acc: 0.0000e+00 - val_loss: 0.1774 - val_acc: 0.0500\n",
      "Epoch 45/200\n",
      "80/80 [==============================] - 0s 349us/step - loss: 0.1604 - acc: 0.0000e+00 - val_loss: 0.1753 - val_acc: 0.0500\n",
      "Epoch 46/200\n",
      "80/80 [==============================] - 0s 347us/step - loss: 0.1589 - acc: 0.0000e+00 - val_loss: 0.1736 - val_acc: 0.0500\n",
      "Epoch 47/200\n",
      "80/80 [==============================] - 0s 346us/step - loss: 0.1575 - acc: 0.0000e+00 - val_loss: 0.1724 - val_acc: 0.0500\n",
      "Epoch 48/200\n",
      "80/80 [==============================] - 0s 345us/step - loss: 0.1560 - acc: 0.0000e+00 - val_loss: 0.1706 - val_acc: 0.0500\n",
      "Epoch 49/200\n",
      "80/80 [==============================] - 0s 355us/step - loss: 0.1545 - acc: 0.0000e+00 - val_loss: 0.1693 - val_acc: 0.0500\n",
      "Epoch 50/200\n",
      "80/80 [==============================] - 0s 367us/step - loss: 0.1529 - acc: 0.0000e+00 - val_loss: 0.1677 - val_acc: 0.0500\n",
      "Epoch 51/200\n",
      "80/80 [==============================] - 0s 359us/step - loss: 0.1513 - acc: 0.0000e+00 - val_loss: 0.1661 - val_acc: 0.0500\n",
      "Epoch 52/200\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.1498 - acc: 0.0000e+00 - val_loss: 0.1641 - val_acc: 0.0500\n",
      "Epoch 53/200\n",
      "80/80 [==============================] - 0s 341us/step - loss: 0.1480 - acc: 0.0000e+00 - val_loss: 0.1624 - val_acc: 0.0500\n",
      "Epoch 54/200\n",
      "80/80 [==============================] - 0s 360us/step - loss: 0.1464 - acc: 0.0000e+00 - val_loss: 0.1604 - val_acc: 0.0500\n",
      "Epoch 55/200\n",
      "80/80 [==============================] - 0s 350us/step - loss: 0.1447 - acc: 0.0000e+00 - val_loss: 0.1582 - val_acc: 0.0500\n",
      "Epoch 56/200\n",
      "80/80 [==============================] - 0s 354us/step - loss: 0.1429 - acc: 0.0000e+00 - val_loss: 0.1560 - val_acc: 0.0500\n",
      "Epoch 57/200\n",
      "80/80 [==============================] - 0s 356us/step - loss: 0.1411 - acc: 0.0000e+00 - val_loss: 0.1537 - val_acc: 0.0500\n",
      "Epoch 58/200\n",
      "80/80 [==============================] - 0s 360us/step - loss: 0.1393 - acc: 0.0000e+00 - val_loss: 0.1518 - val_acc: 0.0500\n",
      "Epoch 59/200\n",
      "80/80 [==============================] - 0s 356us/step - loss: 0.1375 - acc: 0.0000e+00 - val_loss: 0.1505 - val_acc: 0.0500\n",
      "Epoch 60/200\n",
      "80/80 [==============================] - 0s 353us/step - loss: 0.1354 - acc: 0.0000e+00 - val_loss: 0.1482 - val_acc: 0.0500\n",
      "Epoch 61/200\n",
      "80/80 [==============================] - 0s 342us/step - loss: 0.1336 - acc: 0.0000e+00 - val_loss: 0.1455 - val_acc: 0.0500\n",
      "Epoch 62/200\n",
      "80/80 [==============================] - 0s 353us/step - loss: 0.1315 - acc: 0.0000e+00 - val_loss: 0.1427 - val_acc: 0.0500\n",
      "Epoch 63/200\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.1295 - acc: 0.0000e+00 - val_loss: 0.1397 - val_acc: 0.0500\n",
      "Epoch 64/200\n",
      "80/80 [==============================] - 0s 350us/step - loss: 0.1274 - acc: 0.0000e+00 - val_loss: 0.1366 - val_acc: 0.0500\n",
      "Epoch 65/200\n",
      "80/80 [==============================] - 0s 356us/step - loss: 0.1252 - acc: 0.0000e+00 - val_loss: 0.1338 - val_acc: 0.0500\n",
      "Epoch 66/200\n",
      "80/80 [==============================] - 0s 352us/step - loss: 0.1231 - acc: 0.0000e+00 - val_loss: 0.1309 - val_acc: 0.0500\n",
      "Epoch 67/200\n",
      "80/80 [==============================] - 0s 354us/step - loss: 0.1209 - acc: 0.0000e+00 - val_loss: 0.1283 - val_acc: 0.0500\n",
      "Epoch 68/200\n",
      "80/80 [==============================] - 0s 355us/step - loss: 0.1187 - acc: 0.0000e+00 - val_loss: 0.1263 - val_acc: 0.0500\n",
      "Epoch 69/200\n",
      "80/80 [==============================] - 0s 359us/step - loss: 0.1164 - acc: 0.0000e+00 - val_loss: 0.1234 - val_acc: 0.0500\n",
      "Epoch 70/200\n",
      "80/80 [==============================] - 0s 349us/step - loss: 0.1140 - acc: 0.0000e+00 - val_loss: 0.1205 - val_acc: 0.0500\n",
      "Epoch 71/200\n",
      "80/80 [==============================] - 0s 348us/step - loss: 0.1116 - acc: 0.0000e+00 - val_loss: 0.1177 - val_acc: 0.0500\n",
      "Epoch 72/200\n",
      "80/80 [==============================] - 0s 349us/step - loss: 0.1091 - acc: 0.0000e+00 - val_loss: 0.1147 - val_acc: 0.0500\n",
      "Epoch 73/200\n",
      "80/80 [==============================] - 0s 342us/step - loss: 0.1066 - acc: 0.0000e+00 - val_loss: 0.1116 - val_acc: 0.0500\n",
      "Epoch 74/200\n",
      "80/80 [==============================] - 0s 349us/step - loss: 0.1039 - acc: 0.0000e+00 - val_loss: 0.1086 - val_acc: 0.0500\n",
      "Epoch 75/200\n",
      "80/80 [==============================] - 0s 355us/step - loss: 0.1013 - acc: 0.0000e+00 - val_loss: 0.1051 - val_acc: 0.0500\n",
      "Epoch 76/200\n",
      "80/80 [==============================] - 0s 345us/step - loss: 0.0987 - acc: 0.0000e+00 - val_loss: 0.1013 - val_acc: 0.0500\n",
      "Epoch 77/200\n",
      "80/80 [==============================] - 0s 360us/step - loss: 0.0960 - acc: 0.0000e+00 - val_loss: 0.0985 - val_acc: 0.0500\n",
      "Epoch 78/200\n",
      "80/80 [==============================] - 0s 349us/step - loss: 0.0932 - acc: 0.0000e+00 - val_loss: 0.0952 - val_acc: 0.0500\n",
      "Epoch 79/200\n",
      "80/80 [==============================] - 0s 354us/step - loss: 0.0904 - acc: 0.0000e+00 - val_loss: 0.0924 - val_acc: 0.0500\n",
      "Epoch 80/200\n",
      "80/80 [==============================] - 0s 352us/step - loss: 0.0874 - acc: 0.0000e+00 - val_loss: 0.0897 - val_acc: 0.0500\n",
      "Epoch 81/200\n",
      "80/80 [==============================] - 0s 359us/step - loss: 0.0843 - acc: 0.0000e+00 - val_loss: 0.0868 - val_acc: 0.0500\n",
      "Epoch 82/200\n",
      "80/80 [==============================] - 0s 350us/step - loss: 0.0814 - acc: 0.0000e+00 - val_loss: 0.0839 - val_acc: 0.0500\n",
      "Epoch 83/200\n",
      "80/80 [==============================] - 0s 356us/step - loss: 0.0782 - acc: 0.0000e+00 - val_loss: 0.0804 - val_acc: 0.0500\n",
      "Epoch 84/200\n",
      "80/80 [==============================] - 0s 348us/step - loss: 0.0750 - acc: 0.0000e+00 - val_loss: 0.0769 - val_acc: 0.0500\n",
      "Epoch 85/200\n",
      "80/80 [==============================] - 0s 358us/step - loss: 0.0718 - acc: 0.0000e+00 - val_loss: 0.0734 - val_acc: 0.0500\n",
      "Epoch 86/200\n",
      "80/80 [==============================] - 0s 352us/step - loss: 0.0686 - acc: 0.0000e+00 - val_loss: 0.0694 - val_acc: 0.0500\n",
      "Epoch 87/200\n",
      "80/80 [==============================] - 0s 352us/step - loss: 0.0653 - acc: 0.0000e+00 - val_loss: 0.0650 - val_acc: 0.0500\n",
      "Epoch 88/200\n",
      "80/80 [==============================] - 0s 352us/step - loss: 0.0618 - acc: 0.0000e+00 - val_loss: 0.0614 - val_acc: 0.0500\n",
      "Epoch 89/200\n",
      "80/80 [==============================] - 0s 354us/step - loss: 0.0584 - acc: 0.0000e+00 - val_loss: 0.0565 - val_acc: 0.0500\n",
      "Epoch 90/200\n",
      "80/80 [==============================] - 0s 358us/step - loss: 0.0549 - acc: 0.0000e+00 - val_loss: 0.0524 - val_acc: 0.0500\n",
      "Epoch 91/200\n",
      "80/80 [==============================] - 0s 342us/step - loss: 0.0513 - acc: 0.0000e+00 - val_loss: 0.0477 - val_acc: 0.0500\n",
      "Epoch 92/200\n",
      "80/80 [==============================] - 0s 365us/step - loss: 0.0478 - acc: 0.0000e+00 - val_loss: 0.0435 - val_acc: 0.0500\n",
      "Epoch 93/200\n",
      "80/80 [==============================] - 0s 349us/step - loss: 0.0440 - acc: 0.0000e+00 - val_loss: 0.0397 - val_acc: 0.0500\n",
      "Epoch 94/200\n",
      "80/80 [==============================] - 0s 349us/step - loss: 0.0402 - acc: 0.0000e+00 - val_loss: 0.0360 - val_acc: 0.0500\n",
      "Epoch 95/200\n",
      "80/80 [==============================] - 0s 355us/step - loss: 0.0364 - acc: 0.0000e+00 - val_loss: 0.0321 - val_acc: 0.0500\n",
      "Epoch 96/200\n",
      "80/80 [==============================] - 0s 358us/step - loss: 0.0325 - acc: 0.0000e+00 - val_loss: 0.0278 - val_acc: 0.0500\n",
      "Epoch 97/200\n",
      "80/80 [==============================] - 0s 346us/step - loss: 0.0286 - acc: 0.0000e+00 - val_loss: 0.0242 - val_acc: 0.0500\n",
      "Epoch 98/200\n",
      "80/80 [==============================] - 0s 347us/step - loss: 0.0257 - acc: 0.0000e+00 - val_loss: 0.0228 - val_acc: 0.0500\n",
      "Epoch 99/200\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.0234 - acc: 0.0000e+00 - val_loss: 0.0226 - val_acc: 0.0500\n",
      "Epoch 100/200\n",
      "80/80 [==============================] - 0s 350us/step - loss: 0.0218 - acc: 0.0000e+00 - val_loss: 0.0218 - val_acc: 0.0500\n",
      "Epoch 101/200\n",
      "80/80 [==============================] - 0s 349us/step - loss: 0.0208 - acc: 0.0000e+00 - val_loss: 0.0214 - val_acc: 0.0500\n",
      "Epoch 102/200\n",
      "80/80 [==============================] - 0s 346us/step - loss: 0.0203 - acc: 0.0000e+00 - val_loss: 0.0219 - val_acc: 0.0500\n",
      "Epoch 103/200\n",
      "80/80 [==============================] - 0s 353us/step - loss: 0.0200 - acc: 0.0000e+00 - val_loss: 0.0227 - val_acc: 0.0500\n",
      "Epoch 104/200\n",
      "80/80 [==============================] - 0s 357us/step - loss: 0.0198 - acc: 0.0000e+00 - val_loss: 0.0229 - val_acc: 0.0500\n",
      "Epoch 105/200\n",
      "80/80 [==============================] - 0s 348us/step - loss: 0.0198 - acc: 0.0000e+00 - val_loss: 0.0230 - val_acc: 0.0500\n",
      "Epoch 106/200\n",
      "80/80 [==============================] - 0s 347us/step - loss: 0.0197 - acc: 0.0000e+00 - val_loss: 0.0227 - val_acc: 0.0500\n",
      "Epoch 107/200\n",
      "80/80 [==============================] - 0s 348us/step - loss: 0.0196 - acc: 0.0000e+00 - val_loss: 0.0224 - val_acc: 0.0500\n",
      "Epoch 108/200\n",
      "80/80 [==============================] - 0s 349us/step - loss: 0.0196 - acc: 0.0000e+00 - val_loss: 0.0220 - val_acc: 0.0500\n",
      "Epoch 109/200\n",
      "80/80 [==============================] - 0s 352us/step - loss: 0.0196 - acc: 0.0000e+00 - val_loss: 0.0221 - val_acc: 0.0500\n",
      "Epoch 110/200\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.0194 - acc: 0.0000e+00 - val_loss: 0.0229 - val_acc: 0.0500\n",
      "Epoch 111/200\n",
      "80/80 [==============================] - 0s 357us/step - loss: 0.0194 - acc: 0.0000e+00 - val_loss: 0.0238 - val_acc: 0.0500\n",
      "Epoch 112/200\n",
      "80/80 [==============================] - 0s 343us/step - loss: 0.0193 - acc: 0.0000e+00 - val_loss: 0.0234 - val_acc: 0.0500\n",
      "Epoch 113/200\n",
      "80/80 [==============================] - 0s 352us/step - loss: 0.0194 - acc: 0.0000e+00 - val_loss: 0.0221 - val_acc: 0.0500\n",
      "Epoch 114/200\n",
      "80/80 [==============================] - 0s 355us/step - loss: 0.0191 - acc: 0.0000e+00 - val_loss: 0.0219 - val_acc: 0.0500\n",
      "Epoch 115/200\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.0189 - acc: 0.0000e+00 - val_loss: 0.0222 - val_acc: 0.0500\n",
      "Epoch 116/200\n",
      "80/80 [==============================] - 0s 345us/step - loss: 0.0188 - acc: 0.0000e+00 - val_loss: 0.0224 - val_acc: 0.0500\n",
      "Epoch 117/200\n",
      "80/80 [==============================] - 0s 346us/step - loss: 0.0188 - acc: 0.0000e+00 - val_loss: 0.0228 - val_acc: 0.0500\n",
      "Epoch 118/200\n",
      "80/80 [==============================] - 0s 353us/step - loss: 0.0187 - acc: 0.0000e+00 - val_loss: 0.0222 - val_acc: 0.0500\n",
      "Epoch 119/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 350us/step - loss: 0.0185 - acc: 0.0000e+00 - val_loss: 0.0218 - val_acc: 0.0500\n",
      "Epoch 120/200\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.0184 - acc: 0.0000e+00 - val_loss: 0.0218 - val_acc: 0.0500\n",
      "Epoch 121/200\n",
      "80/80 [==============================] - 0s 353us/step - loss: 0.0184 - acc: 0.0000e+00 - val_loss: 0.0215 - val_acc: 0.0500\n",
      "Epoch 122/200\n",
      "80/80 [==============================] - 0s 353us/step - loss: 0.0183 - acc: 0.0000e+00 - val_loss: 0.0210 - val_acc: 0.0500\n",
      "Epoch 123/200\n",
      "80/80 [==============================] - 0s 348us/step - loss: 0.0181 - acc: 0.0000e+00 - val_loss: 0.0215 - val_acc: 0.0500\n",
      "Epoch 124/200\n",
      "80/80 [==============================] - 0s 352us/step - loss: 0.0182 - acc: 0.0000e+00 - val_loss: 0.0217 - val_acc: 0.0500\n",
      "Epoch 125/200\n",
      "80/80 [==============================] - 0s 347us/step - loss: 0.0181 - acc: 0.0000e+00 - val_loss: 0.0207 - val_acc: 0.0500\n",
      "Epoch 126/200\n",
      "80/80 [==============================] - 0s 352us/step - loss: 0.0180 - acc: 0.0000e+00 - val_loss: 0.0203 - val_acc: 0.0500\n",
      "Epoch 127/200\n",
      "80/80 [==============================] - 0s 347us/step - loss: 0.0178 - acc: 0.0000e+00 - val_loss: 0.0209 - val_acc: 0.0500\n",
      "Epoch 128/200\n",
      "80/80 [==============================] - 0s 352us/step - loss: 0.0178 - acc: 0.0000e+00 - val_loss: 0.0212 - val_acc: 0.0500\n",
      "Epoch 129/200\n",
      "80/80 [==============================] - 0s 345us/step - loss: 0.0178 - acc: 0.0000e+00 - val_loss: 0.0209 - val_acc: 0.0500\n",
      "Epoch 130/200\n",
      "80/80 [==============================] - 0s 356us/step - loss: 0.0176 - acc: 0.0000e+00 - val_loss: 0.0204 - val_acc: 0.0500\n",
      "Epoch 131/200\n",
      "80/80 [==============================] - 0s 349us/step - loss: 0.0175 - acc: 0.0000e+00 - val_loss: 0.0203 - val_acc: 0.0500\n",
      "Epoch 132/200\n",
      "80/80 [==============================] - 0s 354us/step - loss: 0.0174 - acc: 0.0000e+00 - val_loss: 0.0203 - val_acc: 0.0500\n",
      "Epoch 133/200\n",
      "80/80 [==============================] - 0s 358us/step - loss: 0.0174 - acc: 0.0000e+00 - val_loss: 0.0202 - val_acc: 0.0500\n",
      "Epoch 134/200\n",
      "80/80 [==============================] - 0s 354us/step - loss: 0.0173 - acc: 0.0000e+00 - val_loss: 0.0202 - val_acc: 0.0500\n",
      "Epoch 135/200\n",
      "80/80 [==============================] - 0s 362us/step - loss: 0.0172 - acc: 0.0000e+00 - val_loss: 0.0203 - val_acc: 0.0500\n",
      "Epoch 136/200\n",
      "80/80 [==============================] - 0s 357us/step - loss: 0.0172 - acc: 0.0000e+00 - val_loss: 0.0199 - val_acc: 0.0500\n",
      "Epoch 137/200\n",
      "80/80 [==============================] - 0s 352us/step - loss: 0.0171 - acc: 0.0000e+00 - val_loss: 0.0196 - val_acc: 0.0500\n",
      "Epoch 138/200\n",
      "80/80 [==============================] - 0s 354us/step - loss: 0.0171 - acc: 0.0000e+00 - val_loss: 0.0197 - val_acc: 0.0500\n",
      "Epoch 139/200\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.0171 - acc: 0.0000e+00 - val_loss: 0.0193 - val_acc: 0.0500\n",
      "Epoch 140/200\n",
      "80/80 [==============================] - 0s 350us/step - loss: 0.0170 - acc: 0.0000e+00 - val_loss: 0.0200 - val_acc: 0.0500\n",
      "Epoch 141/200\n",
      "80/80 [==============================] - 0s 350us/step - loss: 0.0170 - acc: 0.0000e+00 - val_loss: 0.0205 - val_acc: 0.0500\n",
      "Epoch 142/200\n",
      "80/80 [==============================] - 0s 350us/step - loss: 0.0169 - acc: 0.0000e+00 - val_loss: 0.0201 - val_acc: 0.0500\n",
      "Epoch 143/200\n",
      "80/80 [==============================] - 0s 347us/step - loss: 0.0168 - acc: 0.0000e+00 - val_loss: 0.0196 - val_acc: 0.0500\n",
      "Epoch 144/200\n",
      "80/80 [==============================] - 0s 348us/step - loss: 0.0168 - acc: 0.0000e+00 - val_loss: 0.0192 - val_acc: 0.0500\n",
      "Epoch 145/200\n",
      "80/80 [==============================] - 0s 347us/step - loss: 0.0166 - acc: 0.0000e+00 - val_loss: 0.0186 - val_acc: 0.0500\n",
      "Epoch 146/200\n",
      "80/80 [==============================] - 0s 350us/step - loss: 0.0167 - acc: 0.0000e+00 - val_loss: 0.0185 - val_acc: 0.0500\n",
      "Epoch 147/200\n",
      "80/80 [==============================] - 0s 354us/step - loss: 0.0167 - acc: 0.0000e+00 - val_loss: 0.0188 - val_acc: 0.0500\n",
      "Epoch 148/200\n",
      "80/80 [==============================] - 0s 362us/step - loss: 0.0165 - acc: 0.0000e+00 - val_loss: 0.0191 - val_acc: 0.0500\n",
      "Epoch 149/200\n",
      "80/80 [==============================] - 0s 354us/step - loss: 0.0166 - acc: 0.0000e+00 - val_loss: 0.0191 - val_acc: 0.0500\n",
      "Epoch 150/200\n",
      "80/80 [==============================] - 0s 362us/step - loss: 0.0164 - acc: 0.0000e+00 - val_loss: 0.0186 - val_acc: 0.0500\n",
      "Epoch 151/200\n",
      "80/80 [==============================] - 0s 356us/step - loss: 0.0165 - acc: 0.0000e+00 - val_loss: 0.0186 - val_acc: 0.0500\n",
      "Epoch 152/200\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.0165 - acc: 0.0000e+00 - val_loss: 0.0181 - val_acc: 0.0500\n",
      "Epoch 153/200\n",
      "80/80 [==============================] - 0s 345us/step - loss: 0.0164 - acc: 0.0000e+00 - val_loss: 0.0185 - val_acc: 0.0500\n",
      "Epoch 154/200\n",
      "80/80 [==============================] - 0s 350us/step - loss: 0.0164 - acc: 0.0000e+00 - val_loss: 0.0194 - val_acc: 0.0500\n",
      "Epoch 155/200\n",
      "80/80 [==============================] - 0s 347us/step - loss: 0.0164 - acc: 0.0000e+00 - val_loss: 0.0196 - val_acc: 0.0500\n",
      "Epoch 156/200\n",
      "80/80 [==============================] - 0s 352us/step - loss: 0.0165 - acc: 0.0000e+00 - val_loss: 0.0192 - val_acc: 0.0500\n",
      "Epoch 157/200\n",
      "80/80 [==============================] - 0s 358us/step - loss: 0.0162 - acc: 0.0000e+00 - val_loss: 0.0180 - val_acc: 0.0500\n",
      "Epoch 158/200\n",
      "80/80 [==============================] - 0s 352us/step - loss: 0.0165 - acc: 0.0000e+00 - val_loss: 0.0177 - val_acc: 0.0500\n",
      "Epoch 159/200\n",
      "80/80 [==============================] - 0s 360us/step - loss: 0.0165 - acc: 0.0000e+00 - val_loss: 0.0179 - val_acc: 0.0500\n",
      "Epoch 160/200\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.0163 - acc: 0.0000e+00 - val_loss: 0.0188 - val_acc: 0.0500\n",
      "Epoch 161/200\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.0161 - acc: 0.0000e+00 - val_loss: 0.0192 - val_acc: 0.0500\n",
      "Epoch 162/200\n",
      "80/80 [==============================] - 0s 354us/step - loss: 0.0162 - acc: 0.0000e+00 - val_loss: 0.0192 - val_acc: 0.0500\n",
      "Epoch 163/200\n",
      "80/80 [==============================] - 0s 357us/step - loss: 0.0161 - acc: 0.0000e+00 - val_loss: 0.0184 - val_acc: 0.0500\n",
      "Epoch 164/200\n",
      "80/80 [==============================] - 0s 355us/step - loss: 0.0160 - acc: 0.0000e+00 - val_loss: 0.0182 - val_acc: 0.0500\n",
      "Epoch 165/200\n",
      "80/80 [==============================] - 0s 343us/step - loss: 0.0160 - acc: 0.0000e+00 - val_loss: 0.0181 - val_acc: 0.0500\n",
      "Epoch 166/200\n",
      "80/80 [==============================] - 0s 349us/step - loss: 0.0160 - acc: 0.0000e+00 - val_loss: 0.0183 - val_acc: 0.0500\n",
      "Epoch 167/200\n",
      "80/80 [==============================] - 0s 349us/step - loss: 0.0160 - acc: 0.0000e+00 - val_loss: 0.0182 - val_acc: 0.0500\n",
      "Epoch 168/200\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.0160 - acc: 0.0000e+00 - val_loss: 0.0180 - val_acc: 0.0500\n",
      "Epoch 169/200\n",
      "80/80 [==============================] - 0s 348us/step - loss: 0.0159 - acc: 0.0000e+00 - val_loss: 0.0181 - val_acc: 0.0500\n",
      "Epoch 170/200\n",
      "80/80 [==============================] - 0s 347us/step - loss: 0.0159 - acc: 0.0000e+00 - val_loss: 0.0185 - val_acc: 0.0500\n",
      "Epoch 171/200\n",
      "80/80 [==============================] - 0s 356us/step - loss: 0.0159 - acc: 0.0000e+00 - val_loss: 0.0190 - val_acc: 0.0500\n",
      "Epoch 172/200\n",
      "80/80 [==============================] - 0s 345us/step - loss: 0.0160 - acc: 0.0000e+00 - val_loss: 0.0192 - val_acc: 0.0500\n",
      "Epoch 173/200\n",
      "80/80 [==============================] - 0s 354us/step - loss: 0.0159 - acc: 0.0000e+00 - val_loss: 0.0187 - val_acc: 0.0500\n",
      "Epoch 174/200\n",
      "80/80 [==============================] - 0s 359us/step - loss: 0.0158 - acc: 0.0000e+00 - val_loss: 0.0180 - val_acc: 0.0500\n",
      "Epoch 175/200\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.0158 - acc: 0.0000e+00 - val_loss: 0.0179 - val_acc: 0.0500\n",
      "Epoch 176/200\n",
      "80/80 [==============================] - 0s 357us/step - loss: 0.0158 - acc: 0.0000e+00 - val_loss: 0.0180 - val_acc: 0.0500\n",
      "Epoch 177/200\n",
      "80/80 [==============================] - 0s 353us/step - loss: 0.0158 - acc: 0.0000e+00 - val_loss: 0.0182 - val_acc: 0.0500\n",
      "Epoch 178/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 360us/step - loss: 0.0157 - acc: 0.0000e+00 - val_loss: 0.0183 - val_acc: 0.0500\n",
      "Epoch 179/200\n",
      "80/80 [==============================] - 0s 344us/step - loss: 0.0158 - acc: 0.0000e+00 - val_loss: 0.0189 - val_acc: 0.0500\n",
      "Epoch 180/200\n",
      "80/80 [==============================] - 0s 357us/step - loss: 0.0157 - acc: 0.0000e+00 - val_loss: 0.0187 - val_acc: 0.0500\n",
      "Epoch 181/200\n",
      "80/80 [==============================] - 0s 349us/step - loss: 0.0156 - acc: 0.0000e+00 - val_loss: 0.0182 - val_acc: 0.0500\n",
      "Epoch 182/200\n",
      "80/80 [==============================] - 0s 353us/step - loss: 0.0157 - acc: 0.0000e+00 - val_loss: 0.0181 - val_acc: 0.0500\n",
      "Epoch 183/200\n",
      "80/80 [==============================] - 0s 357us/step - loss: 0.0156 - acc: 0.0000e+00 - val_loss: 0.0181 - val_acc: 0.0500\n",
      "Epoch 184/200\n",
      "80/80 [==============================] - 0s 356us/step - loss: 0.0157 - acc: 0.0000e+00 - val_loss: 0.0182 - val_acc: 0.0500\n",
      "Epoch 185/200\n",
      "80/80 [==============================] - 0s 348us/step - loss: 0.0156 - acc: 0.0000e+00 - val_loss: 0.0182 - val_acc: 0.0500\n",
      "Epoch 186/200\n",
      "80/80 [==============================] - 0s 347us/step - loss: 0.0156 - acc: 0.0000e+00 - val_loss: 0.0181 - val_acc: 0.0500\n",
      "Epoch 187/200\n",
      "80/80 [==============================] - 0s 342us/step - loss: 0.0156 - acc: 0.0000e+00 - val_loss: 0.0181 - val_acc: 0.0500\n",
      "Epoch 188/200\n",
      "80/80 [==============================] - 0s 353us/step - loss: 0.0155 - acc: 0.0000e+00 - val_loss: 0.0182 - val_acc: 0.0500\n",
      "Epoch 189/200\n",
      "80/80 [==============================] - 0s 347us/step - loss: 0.0155 - acc: 0.0000e+00 - val_loss: 0.0185 - val_acc: 0.0500\n",
      "Epoch 190/200\n",
      "80/80 [==============================] - 0s 352us/step - loss: 0.0157 - acc: 0.0000e+00 - val_loss: 0.0185 - val_acc: 0.0500\n",
      "Epoch 191/200\n",
      "80/80 [==============================] - 0s 357us/step - loss: 0.0155 - acc: 0.0000e+00 - val_loss: 0.0181 - val_acc: 0.0500\n",
      "Epoch 192/200\n",
      "80/80 [==============================] - 0s 358us/step - loss: 0.0156 - acc: 0.0000e+00 - val_loss: 0.0180 - val_acc: 0.0500\n",
      "Epoch 193/200\n",
      "80/80 [==============================] - 0s 346us/step - loss: 0.0155 - acc: 0.0000e+00 - val_loss: 0.0183 - val_acc: 0.0500\n",
      "Epoch 194/200\n",
      "80/80 [==============================] - 0s 347us/step - loss: 0.0155 - acc: 0.0000e+00 - val_loss: 0.0187 - val_acc: 0.0500\n",
      "Epoch 195/200\n",
      "80/80 [==============================] - 0s 352us/step - loss: 0.0156 - acc: 0.0000e+00 - val_loss: 0.0183 - val_acc: 0.0500\n",
      "Epoch 196/200\n",
      "80/80 [==============================] - 0s 352us/step - loss: 0.0154 - acc: 0.0000e+00 - val_loss: 0.0182 - val_acc: 0.0500\n",
      "Epoch 197/200\n",
      "80/80 [==============================] - 0s 345us/step - loss: 0.0155 - acc: 0.0000e+00 - val_loss: 0.0182 - val_acc: 0.0500\n",
      "Epoch 198/200\n",
      "80/80 [==============================] - 0s 354us/step - loss: 0.0155 - acc: 0.0000e+00 - val_loss: 0.0183 - val_acc: 0.0500\n",
      "Epoch 199/200\n",
      "80/80 [==============================] - 0s 354us/step - loss: 0.0154 - acc: 0.0000e+00 - val_loss: 0.0185 - val_acc: 0.0500\n",
      "Epoch 200/200\n",
      "80/80 [==============================] - 0s 348us/step - loss: 0.0154 - acc: 0.0000e+00 - val_loss: 0.0188 - val_acc: 0.0500\n"
     ]
    }
   ],
   "source": [
    "history2 = model2.fit(x_train, y_train, epochs = 200, validation_data = (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results2 = model2.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(range(20),results2,c='r')\n",
    "plt.scatter(range(20),y_test,c='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_autoencoder",
   "language": "python",
   "name": "env_autoencoder"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
