{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled6.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN2suLV6omwV26jPmeRl5Ue",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Debottam/MachinLearningEx/blob/master/vae_prop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIVmo0BKN39s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "from keras.layers import Lambda, Input, Dense\n",
        "from keras.models import Model\n",
        "from keras.datasets import mnist\n",
        "from keras.losses import mse, binary_crossentropy\n",
        "from keras.utils import plot_model\n",
        "from keras import backend as K\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import argparse\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTaDJ_SNOWtz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reparameterization trick\n",
        "# instead of sampling from Q(z|X), sample epsilon = N(0,I)\n",
        "# z = z_mean + sqrt(var) * epsilon\n",
        "def sampling(args):\n",
        "    \"\"\"Reparameterization trick by sampling from an isotropic unit Gaussian.\n",
        "    # Arguments\n",
        "        args (tensor): mean and log of variance of Q(z|X)\n",
        "    # Returns\n",
        "        z (tensor): sampled latent vector\n",
        "    \"\"\"\n",
        "\n",
        "    z_mean, z_log_var = args\n",
        "    batch = K.shape(z_mean)[0]\n",
        "    dim = K.int_shape(z_mean)[1]\n",
        "    # by default, random_normal has mean = 0 and std = 1.0\n",
        "    epsilon = K.random_normal(shape=(batch, dim))\n",
        "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DffgWZNgOexu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "image_size = x_train.shape[1]\n",
        "original_dim = image_size * image_size\n",
        "x_train = np.reshape(x_train, [-1, original_dim])\n",
        "x_test = np.reshape(x_test, [-1, original_dim])\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sf7lO0lwhYsh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_bkg = x_train[np.where((y_train!=4)&(y_train!=5)&(y_train!=6))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZLm8n_phd1O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7177a6cb-89c2-47a9-f522-175ca039aa1e"
      },
      "source": [
        "x_train_bkg.shape"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(42819, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMwpsUhAeOhC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train_bkg,valid_x_train_bkg = train_test_split(x_train_bkg,\n",
        "                                         test_size=0.2, \n",
        "                                         random_state=13)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11brK47lOhV_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# network parameters\n",
        "input_shape = (original_dim, )\n",
        "intermediate_dim = 512\n",
        "batch_size = 128\n",
        "latent_dim = 2\n",
        "epochs = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jy09WlMUOriw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# VAE model = encoder + decoder\n",
        "# build encoder model\n",
        "inputs = Input(shape=input_shape, name='encoder_input')\n",
        "x = Dense(intermediate_dim, activation='relu')(inputs)\n",
        "z_mean = Dense(latent_dim, name='z_mean')(x)\n",
        "z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
        "\n",
        "# use reparameterization trick to push the sampling out as input\n",
        "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
        "z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntnxtBgtOwmW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "3279aded-e6bd-4f16-df16-fe07dcaa4529"
      },
      "source": [
        "# instantiate encoder model\n",
        "encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
        "encoder.summary()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"encoder\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "encoder_input (InputLayer)      (None, 784)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_11 (Dense)                (None, 512)          401920      encoder_input[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "z_mean (Dense)                  (None, 2)            1026        dense_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "z_log_var (Dense)               (None, 2)            1026        dense_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "z (Lambda)                      (None, 2)            0           z_mean[0][0]                     \n",
            "                                                                 z_log_var[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 403,972\n",
            "Trainable params: 403,972\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uf64zB3O6Pj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build decoder model\n",
        "latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
        "x = Dense(intermediate_dim, activation='relu')(latent_inputs)\n",
        "outputs = Dense(original_dim, activation='sigmoid')(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzGleb7-PGig",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "fbade83c-118f-4f9b-97ef-c9ad77aab152"
      },
      "source": [
        "# instantiate decoder model\n",
        "decoder = Model(latent_inputs, outputs, name='decoder')\n",
        "decoder.summary()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "z_sampling (InputLayer)      (None, 2)                 0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 512)               1536      \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 784)               402192    \n",
            "=================================================================\n",
            "Total params: 403,728\n",
            "Trainable params: 403,728\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnjjzOqzPP4G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# instantiate VAE model\n",
        "outputs = decoder(encoder(inputs)[2])\n",
        "vae = Model(inputs, outputs, name='vae_mlp')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5z96dN-XPXnA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "c09687ed-08c1-4c99-a78a-1930a9da898e"
      },
      "source": [
        "reconstruction_loss = mse(inputs, outputs)\n",
        "reconstruction_loss *= original_dim\n",
        "kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
        "kl_loss = K.sum(kl_loss, axis=-1)\n",
        "kl_loss *= -0.5\n",
        "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
        "vae.add_loss(vae_loss)\n",
        "vae.compile(optimizer='adam')\n",
        "vae.summary()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vae_mlp\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_input (InputLayer)   (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "encoder (Model)              [(None, 2), (None, 2), (N 403972    \n",
            "_________________________________________________________________\n",
            "decoder (Model)              (None, 784)               403728    \n",
            "=================================================================\n",
            "Total params: 807,700\n",
            "Trainable params: 807,700\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Egg7ZyHOPqq_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "201d2401-088a-477a-8c9e-2f3bc0bb1973"
      },
      "source": [
        "vae_hist = vae.fit(x_train_bkg,\n",
        "                   epochs=epochs,\n",
        "                   batch_size=batch_size,\n",
        "                   validation_data=(valid_x_train_bkg, None))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 34255 samples, validate on 8564 samples\n",
            "Epoch 1/50\n",
            "34255/34255 [==============================] - 8s 246us/step - loss: 54.9532 - val_loss: 43.6277\n",
            "Epoch 2/50\n",
            "34255/34255 [==============================] - 8s 225us/step - loss: 42.0825 - val_loss: 41.4047\n",
            "Epoch 3/50\n",
            "34255/34255 [==============================] - 8s 227us/step - loss: 40.8411 - val_loss: 40.5878\n",
            "Epoch 4/50\n",
            "34255/34255 [==============================] - 8s 225us/step - loss: 40.1002 - val_loss: 39.8223\n",
            "Epoch 5/50\n",
            "34255/34255 [==============================] - 8s 227us/step - loss: 39.4844 - val_loss: 39.3035\n",
            "Epoch 6/50\n",
            "34255/34255 [==============================] - 8s 224us/step - loss: 38.9849 - val_loss: 38.8921\n",
            "Epoch 7/50\n",
            "34255/34255 [==============================] - 8s 227us/step - loss: 38.5747 - val_loss: 38.4649\n",
            "Epoch 8/50\n",
            "34255/34255 [==============================] - 8s 227us/step - loss: 38.2579 - val_loss: 38.2242\n",
            "Epoch 9/50\n",
            "34255/34255 [==============================] - 8s 226us/step - loss: 37.9770 - val_loss: 37.8886\n",
            "Epoch 10/50\n",
            "34255/34255 [==============================] - 8s 226us/step - loss: 37.7167 - val_loss: 37.7802\n",
            "Epoch 11/50\n",
            "34255/34255 [==============================] - 8s 224us/step - loss: 37.5158 - val_loss: 37.5518\n",
            "Epoch 12/50\n",
            "34255/34255 [==============================] - 8s 225us/step - loss: 37.3090 - val_loss: 37.3701\n",
            "Epoch 13/50\n",
            "34255/34255 [==============================] - 8s 226us/step - loss: 37.1388 - val_loss: 37.2608\n",
            "Epoch 14/50\n",
            "34255/34255 [==============================] - 8s 223us/step - loss: 36.9639 - val_loss: 37.1340\n",
            "Epoch 15/50\n",
            "34255/34255 [==============================] - 8s 227us/step - loss: 36.8251 - val_loss: 37.0115\n",
            "Epoch 16/50\n",
            "34255/34255 [==============================] - 8s 240us/step - loss: 36.6861 - val_loss: 36.8991\n",
            "Epoch 17/50\n",
            "34255/34255 [==============================] - 8s 232us/step - loss: 36.5610 - val_loss: 36.7747\n",
            "Epoch 18/50\n",
            "34255/34255 [==============================] - 8s 226us/step - loss: 36.4410 - val_loss: 36.6623\n",
            "Epoch 19/50\n",
            "34255/34255 [==============================] - 8s 225us/step - loss: 36.3440 - val_loss: 36.6229\n",
            "Epoch 20/50\n",
            "34255/34255 [==============================] - 8s 224us/step - loss: 36.2773 - val_loss: 36.5333\n",
            "Epoch 21/50\n",
            "34255/34255 [==============================] - 8s 225us/step - loss: 36.1917 - val_loss: 36.4920\n",
            "Epoch 22/50\n",
            "34255/34255 [==============================] - 8s 226us/step - loss: 36.0891 - val_loss: 36.4263\n",
            "Epoch 23/50\n",
            "34255/34255 [==============================] - 8s 226us/step - loss: 35.9761 - val_loss: 36.3553\n",
            "Epoch 24/50\n",
            "34255/34255 [==============================] - 8s 225us/step - loss: 35.9310 - val_loss: 36.2806\n",
            "Epoch 25/50\n",
            "34255/34255 [==============================] - 8s 225us/step - loss: 35.8433 - val_loss: 36.2818\n",
            "Epoch 26/50\n",
            "34255/34255 [==============================] - 8s 224us/step - loss: 35.7649 - val_loss: 36.2188\n",
            "Epoch 27/50\n",
            "34255/34255 [==============================] - 8s 226us/step - loss: 35.7088 - val_loss: 36.2361\n",
            "Epoch 28/50\n",
            "34255/34255 [==============================] - 8s 225us/step - loss: 35.6657 - val_loss: 36.1105\n",
            "Epoch 29/50\n",
            "34255/34255 [==============================] - 8s 223us/step - loss: 35.5944 - val_loss: 36.0554\n",
            "Epoch 30/50\n",
            "34255/34255 [==============================] - 8s 224us/step - loss: 35.5647 - val_loss: 36.0238\n",
            "Epoch 31/50\n",
            "34255/34255 [==============================] - 8s 226us/step - loss: 35.4998 - val_loss: 35.9438\n",
            "Epoch 32/50\n",
            "34255/34255 [==============================] - 8s 225us/step - loss: 35.4435 - val_loss: 35.9921\n",
            "Epoch 33/50\n",
            "34255/34255 [==============================] - 8s 225us/step - loss: 35.3853 - val_loss: 35.8989\n",
            "Epoch 34/50\n",
            "34255/34255 [==============================] - 8s 224us/step - loss: 35.3319 - val_loss: 35.9291\n",
            "Epoch 35/50\n",
            "34255/34255 [==============================] - 8s 224us/step - loss: 35.3030 - val_loss: 35.8902\n",
            "Epoch 36/50\n",
            "34255/34255 [==============================] - 8s 224us/step - loss: 35.2601 - val_loss: 35.9036\n",
            "Epoch 37/50\n",
            "34255/34255 [==============================] - 8s 224us/step - loss: 35.1978 - val_loss: 35.9043\n",
            "Epoch 38/50\n",
            "34255/34255 [==============================] - 8s 226us/step - loss: 35.1720 - val_loss: 35.8902\n",
            "Epoch 39/50\n",
            "34255/34255 [==============================] - 8s 226us/step - loss: 35.1551 - val_loss: 35.8146\n",
            "Epoch 40/50\n",
            "34255/34255 [==============================] - 8s 225us/step - loss: 35.1204 - val_loss: 35.8011\n",
            "Epoch 41/50\n",
            "34255/34255 [==============================] - 8s 226us/step - loss: 35.0695 - val_loss: 35.7845\n",
            "Epoch 42/50\n",
            "34255/34255 [==============================] - 8s 225us/step - loss: 35.0474 - val_loss: 35.7544\n",
            "Epoch 43/50\n",
            "34255/34255 [==============================] - 8s 227us/step - loss: 35.0088 - val_loss: 35.7948\n",
            "Epoch 44/50\n",
            "34255/34255 [==============================] - 8s 226us/step - loss: 34.9766 - val_loss: 35.6779\n",
            "Epoch 45/50\n",
            "34255/34255 [==============================] - 8s 225us/step - loss: 34.9310 - val_loss: 35.7615\n",
            "Epoch 46/50\n",
            "34255/34255 [==============================] - 8s 227us/step - loss: 34.9314 - val_loss: 35.6652\n",
            "Epoch 47/50\n",
            "34255/34255 [==============================] - 8s 227us/step - loss: 34.8520 - val_loss: 35.7107\n",
            "Epoch 48/50\n",
            "34255/34255 [==============================] - 8s 223us/step - loss: 34.8619 - val_loss: 35.7145\n",
            "Epoch 49/50\n",
            "34255/34255 [==============================] - 8s 224us/step - loss: 34.7988 - val_loss: 35.6440\n",
            "Epoch 50/50\n",
            "34255/34255 [==============================] - 8s 223us/step - loss: 34.7839 - val_loss: 35.5569\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPjiBJzqS-gt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "db2c2474-6793-427b-b134-9479f2d3b971"
      },
      "source": [
        "loss = vae_hist.history['loss']\n",
        "val_loss = vae_hist.history['val_loss']\n",
        "epochs = range(50)\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}