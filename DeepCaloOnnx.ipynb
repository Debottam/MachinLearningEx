{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepcalo as dpcal\n",
    "import json\n",
    "import keras as ks\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import onnxruntime as ort\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tf2onnx\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import import_module\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2.3\n",
      "3.8.6 (v3.8.6:db455296be, Sep 23 2020, 13:31:39) \n",
      "[Clang 6.0 (clang-600.0.57)]\n",
      "1.7.0\n",
      "1.8.5\n"
     ]
    }
   ],
   "source": [
    "print(dpcal.__version__)\n",
    "print(sys.version)\n",
    "print(ort.__version__)\n",
    "print(tf2onnx.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combine_model.0008-31.3847.hdf5 model.0046-2.9464.json\r\n",
      "dataparams.pkl                  model.h5\r\n",
      "dataparams.txt                  weights.0046-2.9464.hdf5\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../Downloads/Zee_mc_1000_epochs_3_8_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Downloads/Zee_mc_1000_epochs_3_8_5/model.0046-2.9464.json\n"
     ]
    }
   ],
   "source": [
    "model_path = '../Downloads/Zee_mc_1000_epochs_3_8_5/model.0046-2.9464.json'\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(model_path, 'r') as model_json:\n",
    "    arch = json.load(model_json)\n",
    "    model = ks.models.model_from_json(arch, custom_objects={'FiLM': dpcal.layers.FiLM()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "em_barrel (InputLayer)          [(None, 56, 11, 4)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "scalars (InputLayer)            [(None, 16)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 56, 55, 4)    0           em_barrel[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "scalar_net (Functional)         (None, 256)          5120        scalars[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 56, 55, 4)    0           up_sampling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "FiLM_generator (Functional)     [(None, 32), (None,  1678304     scalar_net[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "cnn (Functional)                (None, 3, 3, 256)    1180528     lambda[0][0]                     \n",
      "                                                                 FiLM_generator[0][0]             \n",
      "                                                                 FiLM_generator[0][1]             \n",
      "                                                                 FiLM_generator[0][2]             \n",
      "                                                                 FiLM_generator[0][3]             \n",
      "                                                                 FiLM_generator[0][4]             \n",
      "__________________________________________________________________________________________________\n",
      "tracks (InputLayer)             [(None, 10, 13, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 2304)         0           cnn[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Functional)            (None, 32)           8970        tracks[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 2336)         0           flatten_1[0][0]                  \n",
      "                                                                 model_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "top (Functional)                (None, 1)            665857      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "multiply_output_with (InputLaye [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "event_info (InputLayer)         [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 1)            0           top[0][0]                        \n",
      "                                                                 multiply_output_with[0][0]       \n",
      "==================================================================================================\n",
      "Total params: 3,538,779\n",
      "Trainable params: 3,532,071\n",
      "Non-trainable params: 6,708\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"../Downloads/Zee_mc_1000_epochs_3_8_5/weights.0046-2.9464.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = (\n",
    "\n",
    "    tf.TensorSpec((None,  5), tf.float32, name=\"event_info\"),\n",
    "\n",
    "    tf.TensorSpec((None,  10, 13, 1), tf.float32, name=\"tracks\"),\n",
    "\n",
    "    tf.TensorSpec((None,  56, 11, 4), tf.float32, name=\"em_barrel\"),\n",
    "\n",
    "    tf.TensorSpec((None,  1), tf.float32, name=\"multiply_output_with\"),\n",
    "\n",
    "    tf.TensorSpec((None,  16), tf.float32, name=\"scalars\"),\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert keras model to Onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_proto, _ = tf2onnx.convert.from_keras(\n",
    "\n",
    "    model, input_signature=spec, opset=13, output_path=\"../Downloads/model.0046_2.9464.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating the Onnx model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess_ort = ort.InferenceSession(\"../Downloads/model.0046_2.9464.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event_info : ['unk__451', 5]\n",
      "tracks : ['unk__452', 10, 13, 1]\n",
      "em_barrel : ['unk__453', 56, 11, 4]\n",
      "multiply_output_with : ['unk__454', 1]\n",
      "scalars : ['unk__455', 16]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(sess_ort.get_inputs())):\n",
    "    print(sess_ort.get_inputs()[i].name,\":\",sess_ort.get_inputs()[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_name multiply\n",
      "output shape ['unk__456', 1]\n",
      "output type tensor(float)\n"
     ]
    }
   ],
   "source": [
    "output_name = sess_ort.get_outputs()[0].name\n",
    "print(\"output_name\", output_name)\n",
    "output_shape = sess_ort.get_outputs()[0].shape\n",
    "print(\"output shape\", output_shape)\n",
    "output_type = sess_ort.get_outputs()[0].type\n",
    "print(\"output type\", output_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = onnx.load('../Downloads/model.0046_2.9464.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = []\n",
    "for o in m.graph.output:\n",
    "        output.append(o.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['multiply']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filenames, tag,data_params, batch_size=2048, load_single_file=False, shuffle=True, merge=True,\n",
    "                 additional_info=True, cache=False, multiple_with=True, cut_ratio=None,\n",
    "                 training_in_data=False, autotune = tf.data.experimental.AUTOTUNE,time_lr= False, ext_energy_range=None): \n",
    "    options = tf.data.Options()\n",
    "    \n",
    "    # print(autotune)\n",
    "    options.experimental_deterministic = not shuffle!=0\n",
    "    options.experimental_threading.private_threadpool_size = 16\n",
    "    \n",
    "    file_path = tf.data.Dataset.list_files(filenames, shuffle=shuffle!=0\n",
    "                                           ).with_options(options)\n",
    "    dataset = tf.data.TFRecordDataset(\n",
    "        file_path, compression_type='GZIP', num_parallel_reads=1 if load_single_file else autotune #autotune\n",
    "        ).prefetch(buffer_size=autotune)  # automatically interleaves reads from multiple files tf.data.experimental.AUTOTUNE\n",
    "    \n",
    "    dataset = dataset.map(lambda x: read_tfrecord_new(x, tag, merge=merge,data_params=data_params),\n",
    "                                                          num_parallel_calls=autotune)\n",
    "\n",
    "    if shuffle:\n",
    "        if isinstance(shuffle, bool):\n",
    "            dataset = dataset.shuffle(12)\n",
    "        else:\n",
    "            dataset = dataset.shuffle(shuffle)\n",
    "    if cut_ratio != None:\n",
    "        dataset = dataset.filter(lambda x, label: tf.math.abs(x['event_info'][0]/label-1) < cut_ratio)\n",
    "    if ext_energy_range != None:\n",
    "        if ext_energy_range ==0:\n",
    "            dataset = dataset.filter(lambda x, label: label/tf.math.cosh(x['event_info'][1]) > ext_energy_range)\n",
    "        elif ext_energy_range > 0:\n",
    "            dataset = dataset.filter(lambda x, label: label/tf.math.cosh(x['event_info'][1]) < ext_energy_range)\n",
    "        elif ext_energy_range < 0:\n",
    "            dataset = dataset.filter(lambda x, label: label/tf.math.cosh(x['event_info'][1]) > -ext_energy_range)\n",
    "\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=False)\n",
    "    if cache:\n",
    "        dataset = dataset.cache()    \n",
    "        # pass\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tfrecord_new(example, tag, data_params, merge=True):\n",
    "    data ={}\n",
    "    tfrecord_format = {\n",
    "                    \"em_barrel_Lr0\": tf.io.FixedLenFeature([56,11,], tf.float32),\n",
    "                    \"em_barrel_Lr1\": tf.io.FixedLenFeature([56,11,], tf.float32),\n",
    "                    \"em_barrel_Lr2\": tf.io.FixedLenFeature([56,11,], tf.float32),\n",
    "                    \"em_barrel_Lr3\": tf.io.FixedLenFeature([56,11,], tf.float32),\n",
    "                    \"targets\": tf.io.FixedLenFeature([], tf.float32),\n",
    "                    \"multiply_output_name\": tf.io.FixedLenFeature([], tf.float32)\n",
    "                        }\n",
    "    for sca in data_params['scalar_names']:\n",
    "        tfrecord_format[sca] = tf.io.FixedLenFeature([], tf.float32)\n",
    "    for tra in data_params['track_names']:\n",
    "        tfrecord_format[tra] = tf.io.FixedLenFeature([10,], tf.float32)\n",
    "    for gate in data_params['gate_img_prefix']:\n",
    "        names = ['_Lr0', '_Lr1', '_Lr2', '_Lr3']\n",
    "        for i in names:\n",
    "            tfrecord_format[gate+i] = tf.io.FixedLenFeature([56,11,], tf.float32)\n",
    "    if data_params['additional_info']:\n",
    "        if (tag=='Zmumugam'):\n",
    "            tfrecord_format['event_info'] = tf.io.FixedLenFeature([15,], tf.float32)\n",
    "        else:\n",
    "            tfrecord_format['event_info'] = tf.io.FixedLenFeature([5,], tf.float32)\n",
    "    dataset = tf.io.parse_single_example(example, tfrecord_format)\n",
    "    data = {name: tf.cast(dataset[name], tf.float32, name=name) for name in tfrecord_format.keys()}\n",
    "    label = data['targets']\n",
    "    data.pop('targets')\n",
    "\n",
    "    if merge: # merge all the images together so the channel = 4\n",
    "        data['em_barrel']  = tf.stack([data['em_barrel_Lr0'], data['em_barrel_Lr1'], data['em_barrel_Lr2'], data['em_barrel_Lr3']], axis=-1)\n",
    "        [data.pop(i) for i in [\"em_barrel_Lr0\", \"em_barrel_Lr1\", \"em_barrel_Lr2\", \"em_barrel_Lr3\"]]\n",
    "        # if 'time_em_barrel_Lr0' in tfrecord_format.keys():     \n",
    "        for gate in data_params['gate_img_prefix']:\n",
    "            data[gate]  = tf.stack([data[gate+'_Lr0'], data[gate+'_Lr1'], data[gate+'_Lr2'], data[gate+'_Lr3']], axis=-1)\n",
    "            [data.pop(i) for i in [gate+'_Lr0', gate+'_Lr1', gate+'_Lr2', gate+'_Lr3']]\n",
    "            # data[gate] = tf.math.abs(data[gate])# <= 0.05 ## abs\n",
    "    for i in ['track_names', 'scalar_names']:\n",
    "        if data_params[i]:\n",
    "            tracks = [data[i] for i in data_params[i]]\n",
    "            data[i.split('_')[0]+'s']  = tf.stack(tracks, axis=-1 if i=='track_names' else 0)\n",
    "            [data.pop(i) for i in data_params[i]]\n",
    "    return data, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  5.14it/s]\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\" # -1 disable\n",
    "if True:\n",
    "    data = {}\n",
    "\n",
    "    files = glob.glob('*.tfrecords') ## change dir\n",
    "            \n",
    "    tag = 'Zee'\n",
    "        \n",
    "    # data_path = f'../tfrecords_data/{tag}'\n",
    "    particle = 'electrons' if tag=='Zee' else 'photons'\n",
    "    data_conf = import_module(f'..{particle}_variables_conf',  'variables_params.subpkg')\n",
    "    data_params = data_conf.get_params()\n",
    "    if True:\n",
    "        size = 0\n",
    "        target = []\n",
    "            \n",
    "        time_image=[]\n",
    "        em_image=[]\n",
    "        scalar = []\n",
    "        event_info=[]\n",
    "        tracks=[]\n",
    "        multiply_output_name=[]\n",
    "        nr_of_cores= 8\n",
    "        train= load_dataset(files[:],#files[:1],\n",
    "                            tag=tag, shuffle=False, merge=True, load_single_file=True,\n",
    "                            additional_info=True, autotune = nr_of_cores,\n",
    "                            batch_size=500, time_lr = data_params['gate_img_prefix'], \n",
    "                            data_params=data_params, cut_ratio=None,\n",
    "                            ext_energy_range=None).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "        n=1\n",
    "        nr =0\n",
    "        time=[]\n",
    "        for t, e in tqdm(train.take(n), total = n):\n",
    "            size += len(e)\n",
    "\n",
    "            target.append(e.numpy())\n",
    "            event_info.append(t['event_info'].numpy())\n",
    "            scalar.append(t['scalars'].numpy())\n",
    "            tracks.append(t['tracks'].numpy())\n",
    "            multiply_output_name.append(t['multiply_output_name'].numpy())\n",
    "            time_image.append(t['time_em_barrel'].numpy())\n",
    "            em_image.append(t['em_barrel'].numpy())\n",
    "            nr +=1\n",
    "for i,j in zip([event_info, scalar, tracks, multiply_output_name,\n",
    "                    time_image, em_image],['event_info', 'scalars', 'tracks',\n",
    "                                           'multiply_output_name', 'time_em_barrel',\n",
    "                                           'em_barrel']):\n",
    "    data[j] = np.array(i)\n",
    "        \n",
    "    '''It is MC. Now data should be the input to the model and target the target'''\n",
    "    '''You should be able to just import tfrecord_load_data'''\n",
    "    '''and then run the line above to import the data'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['event_info', 'scalars', 'tracks', 'multiply_output_name', 'time_em_barrel', 'em_barrel'])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event_info:  (1, 500, 5)\n",
      "scalars:  (1, 500, 16)\n",
      "tracks:  (1, 500, 10, 13)\n",
      "multiply_output_name:  (1, 500)\n",
      "time_em_barrel:  (1, 500, 56, 11, 4)\n",
      "em_barrel:  (1, 500, 56, 11, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"event_info: \",data['event_info'].shape)\n",
    "print(\"scalars: \",data['scalars'].shape)\n",
    "print(\"tracks: \",data['tracks'].shape)\n",
    "print(\"multiply_output_name: \",data['multiply_output_name'].shape)\n",
    "print(\"time_em_barrel: \",data['time_em_barrel'].shape)\n",
    "print(\"em_barrel: \",data['em_barrel'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['event_info'] = data['event_info'].reshape(500,5)\n",
    "data['scalars'] = data['scalars'].reshape(500,16)\n",
    "data['tracks'] = data['tracks'].reshape(500,10, 13,1)\n",
    "data['multiply_output_name'] = data['multiply_output_name'].reshape(500,1)\n",
    "data['time_em_barrel'] = data['time_em_barrel'].reshape(500,56, 11, 4)\n",
    "data['em_barrel'] = data['em_barrel'].reshape(500,56, 11, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event_info:  (500, 5)\n",
      "scalars:  (500, 16)\n",
      "tracks:  (500, 10, 13, 1)\n",
      "multiply_output_name:  (500, 1)\n",
      "time_em_barrel:  (500, 56, 11, 4)\n",
      "em_barrel:  (500, 56, 11, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"event_info: \",data['event_info'].shape)\n",
    "print(\"scalars: \",data['scalars'].shape)\n",
    "print(\"tracks: \",data['tracks'].shape)\n",
    "print(\"multiply_output_name: \",data['multiply_output_name'].shape)\n",
    "print(\"time_em_barrel: \",data['time_em_barrel'].shape)\n",
    "print(\"em_barrel: \",data['em_barrel'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sess_ort.get_inputs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_feeds = {}\n",
    "key = ['event_info', 'tracks', 'time_em_barrel','multiply_output_name', 'scalars']\n",
    "for i in range(5):\n",
    "    input_feeds[sess_ort.get_inputs()[i].name] = data[key[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: input_feeds: command not found\r\n"
     ]
    }
   ],
   "source": [
    "!input_feeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kerasPredict = model.predict(input_feeds)\n",
    "kerasPredict_list = list(kerasPredict)\n",
    "len(kerasPredict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnxPredict = sess_ort.run(output, input_feeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnxPredict_np = np.array(onnxPredict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onnxPredict_np = onnxPredict_np.reshape(500,1)\n",
    "onnxPredict_list = list(onnxPredict_np)\n",
    "len(onnxPredict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([3947.143], dtype=float32),\n",
       " array([380.76245], dtype=float32),\n",
       " array([0.], dtype=float32),\n",
       " array([241.66402], dtype=float32),\n",
       " array([266.27936], dtype=float32),\n",
       " array([433.56155], dtype=float32),\n",
       " array([462.17758], dtype=float32),\n",
       " array([0.], dtype=float32),\n",
       " array([260.5142], dtype=float32),\n",
       " array([91.381966], dtype=float32)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kerasPredict_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([3947.1467], dtype=float32),\n",
       " array([380.76288], dtype=float32),\n",
       " array([0.], dtype=float32),\n",
       " array([241.66383], dtype=float32),\n",
       " array([266.27927], dtype=float32),\n",
       " array([433.56192], dtype=float32),\n",
       " array([462.1776], dtype=float32),\n",
       " array([0.], dtype=float32),\n",
       " array([260.5143], dtype=float32),\n",
       " array([91.38199], dtype=float32)]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onnxPredict_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(kerasPredict_list, label='kerasModel')\n",
    "plt.plot(onnxPredict_list, label='onnxModel')\n",
    "plt.title('output from inference')\n",
    "plt.ylim(0, 600)\n",
    "plt.xlim(0, 10)\n",
    "plt.xlabel('batchSize')\n",
    "plt.ylabel('Modeloutpt')\n",
    "plt.legend(loc='upper right')\n",
    "plt.rcParams[\"figure.figsize\"] = (10,6)\n",
    "plt.savefig('../Downloads/kerasVsOnnx_1.png', dpi = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Dpenv",
   "language": "python",
   "name": "dpenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
