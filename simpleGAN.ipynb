{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled7.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO589HiVe2XyUkRMNHWhtZ9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Debottam/MachinLearningEx/blob/master/simpleGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VxfSB_u7CjB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import zeros, hstack, ones\n",
        "from numpy.random import rand, randn\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from matplotlib import pyplot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijVRenYM8PL5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define standalone discriminator model\n",
        "def define_discriminator(n_inputs = 2):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(25, activation= 'relu', kernel_initializer= 'he_uniform', input_dim = n_inputs))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  #compile model\n",
        "  model.compile(loss = 'binary_crossentropy', optmizer = 'adam', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "#define standalone generator model\n",
        "def define_discriminator(latent_dim, n_outputs = 2):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(15, activation= 'relu', kernel_initializer= 'he_uniform', input_dim = latent_dim))\n",
        "  model.add(Dense(n_outputs, activation='linear'))\n",
        "  #compile model\n",
        "  model.compile(loss = 'binary_crossentropy', optmizer = 'adam', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "#define combine generator and discriminator model to train generator alone\n",
        "def define_gan(generator, discriminator):\n",
        "  #make weights in discriminator not trainable\n",
        "  discriminator.trainable = False\n",
        "  #connect them\n",
        "  model = Sequential()\n",
        "  model.add(generator)\n",
        "  model.add(discriminator)\n",
        "  model.compile(loss = 'binary_crossentropy', optmizer = 'adam')\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1x3IlF0HENou",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate n real sample with class label\n",
        "def generate_real_samples(n):\n",
        "  # generate input in -0.5 and 0.5\n",
        "  X1 = rand(n)- 0.5\n",
        "  # generate output X^2\n",
        "  X2 = X1*X1\n",
        "  # stack arrays\n",
        "  X1 = X1.reshape(n,1)\n",
        "  X2 = X2.reshape(n,1)\n",
        "  X = hstack((X1,X2))\n",
        "  # generate class label\n",
        "  y = ones((n, 1))\n",
        "  return X,y\n",
        "\n",
        "# generate latent space as input to generator\n",
        "def generate_latent_points(latent_dim, n):\n",
        "  # generate points in the latent space\n",
        "  x_input = randn(latent_dim*n)\n",
        "  x_input = x_input.reshape(n,latent_dim)\n",
        "  return x_input\n",
        "\n",
        "# use generator to generate fake example\n",
        "def generate_fake_samples(generator, latent_dim, n):\n",
        "  # generate points in latent space\n",
        "  x_input = generate_latent_points(latent_dim, n)\n",
        "  # predict output\n",
        "  X = generator.predict(x_input)\n",
        "  # generate class label\n",
        "  y = zeros((n, 1))\n",
        "  return X,y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDpc8gPNQVAN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluate the discriminator an plot real and fake points\n",
        "def summarize_performance(epoch, generator, discriminator, latent_dim, n=100):\n",
        "  # prepare real sample\n",
        "  x_real, y_real = generate_real_samples(n)\n",
        "  # evaluate discriminator on real sample\n",
        "  _, acc_real = discriminator.evaluate(x_real, y_real,verbose =0)\n",
        "  # prepare fake sample\n",
        "  x_fake, y_fake = generate_fake_samples(generator, latent_dim, n)\n",
        "  # evaluate discriminator on fake sample\n",
        "  _, acc_fake = discriminator.evaluate(x_fake, y_fake,verbose =0)\n",
        "  print(epoch, acc_real, acc_fake)\n",
        "  # scatter plot real and fake data points\n",
        "  pyplot.scatter(x_real[:,0], x_real[:,1], color = 'red')\n",
        "  pyplot.scatter(x_fake[:,0], x_fake[:,1], color = 'blue')\n",
        "\n",
        "# Train the generator and discriminator\n",
        "def train (g_model, d_model, gan_model, latent_dim, n_epochs= 10000, n_batch= 128, n_eval= 2000):\n",
        "  # half batch for updating the discriminator\n",
        "  half_batch = int(n_batch/2)\n",
        "  for i in range(n_epochs):\n",
        "    # prepare real sample\n",
        "    x_real, y_real = generate_real_samples(n_batch)\n",
        "    # prepare fake sample\n",
        "    x_fake, y_fake = generate_fake_samples(g_model, latent_dim, n_batch)\n",
        "    # update discriminator\n",
        "    d_model.train_on_batch(x_real, y_real)\n",
        "    d_model.train_on_batch(x_fake, y_fake)\n",
        "    # prepare point for the latent space as input to generator\n",
        "    x_gan = generate_latent_points(latent_dim, n_batch)\n",
        "    # create inverted labels for the fake samples\n",
        "    y_gan = ones((n_batch, 1))\n",
        "    # update generator via discriminator's error\n",
        "    gan_model.train_on_batch(x_gan, y_gan)\n",
        "    # evaluate the model in every n_eval epoch\n",
        "    if (i+1)%n_eval == 0:\n",
        "      summarize_performance(i, g_model, d_model, latent_dim, n=100)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhHJ61L1e-Yx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# size of the latent space\n",
        "latent_dim = 5\n",
        "# create the discriminator\n",
        "discriminator = define_discriminator()\n",
        "# create the discriminator\n",
        "generator = define_generator(latent_dim)\n",
        "# create a GAN\n",
        "gan_model = define_gan(generator, discriminator)\n",
        "# train model\n",
        "train(g_model, d_model, gan_model, latent_dim)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}